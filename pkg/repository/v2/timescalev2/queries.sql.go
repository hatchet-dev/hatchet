// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.24.0
// source: queries.sql

package timescalev2

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const countTasks = `-- name: CountTasks :one
WITH filtered AS (
    SELECT
        tenant_id, id, inserted_at, external_id, queue, action_id, step_id, workflow_id, schedule_timeout, step_timeout, priority, sticky, desired_worker_id, display_name, input, additional_metadata, readable_status, latest_retry_count, latest_worker_id, dag_id, dag_inserted_at
    FROM
        v2_tasks_olap
    WHERE
        tenant_id = $1::uuid
        AND inserted_at >= $2::timestamptz
        AND (
            $3::timestamptz IS NULL
            OR inserted_at <= $3::timestamptz
        )
        AND (
            $4::text[] IS NULL OR readable_status = ANY(cast($4::text[] as v2_readable_status_olap[]))
        )
        AND (
            $5::uuid[] IS NULL OR workflow_id = ANY($5::uuid[])
        )
        AND (
            $6::uuid IS NULL OR latest_worker_id = $6::uuid
        )
        AND (
            $7::text[] IS NULL
            OR $8::text[] IS NULL
            OR EXISTS (
                SELECT 1 FROM jsonb_each_text(additional_metadata) kv
                JOIN LATERAL (
                    SELECT unnest($7::text[]) AS k,
                        unnest($8::text[]) AS v
                ) AS u ON kv.key = u.k AND kv.value = u.v
            )
        )
    ORDER BY
        inserted_at DESC
    LIMIT 20000
)

SELECT COUNT(*)
FROM filtered
`

type CountTasksParams struct {
	Tenantid    pgtype.UUID        `json:"tenantid"`
	Since       pgtype.Timestamptz `json:"since"`
	Until       pgtype.Timestamptz `json:"until"`
	Statuses    []string           `json:"statuses"`
	WorkflowIds []pgtype.UUID      `json:"workflowIds"`
	WorkerId    pgtype.UUID        `json:"workerId"`
	Keys        []string           `json:"keys"`
	Values      []string           `json:"values"`
}

func (q *Queries) CountTasks(ctx context.Context, db DBTX, arg CountTasksParams) (int64, error) {
	row := db.QueryRow(ctx, countTasks,
		arg.Tenantid,
		arg.Since,
		arg.Until,
		arg.Statuses,
		arg.WorkflowIds,
		arg.WorkerId,
		arg.Keys,
		arg.Values,
	)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countWorkflowRuns = `-- name: CountWorkflowRuns :one
WITH filtered AS (
    SELECT tenant_id, id, inserted_at, external_id, readable_status, kind, workflow_id, additional_metadata
    FROM v2_runs_olap
    WHERE
        tenant_id = $1::uuid
        AND (
            $2::uuid[] IS NULL
            OR workflow_id = ANY($2::uuid[])
        )
        AND (
            $3::text[] IS NULL
            OR readable_status = ANY(cast($3::text[] as v2_readable_status_olap[]))
        )
        AND inserted_at >= $4::timestamptz
        AND (
            $5::timestamptz IS NULL
            OR inserted_at <= $5::timestamptz
        )
        AND (
            $6::text[] IS NULL
            OR $7::text[] IS NULL
            OR EXISTS (
                SELECT 1 FROM jsonb_each_text(additional_metadata) kv
                JOIN LATERAL (
                    SELECT unnest($6::text[]) AS k,
                        unnest($7::text[]) AS v
                ) AS u ON kv.key = u.k AND kv.value = u.v
            )
        )
    LIMIT 20000
)

SELECT COUNT(*)
FROM filtered
`

type CountWorkflowRunsParams struct {
	Tenantid    pgtype.UUID        `json:"tenantid"`
	WorkflowIds []pgtype.UUID      `json:"workflowIds"`
	Statuses    []string           `json:"statuses"`
	Since       pgtype.Timestamptz `json:"since"`
	Until       pgtype.Timestamptz `json:"until"`
	Keys        []string           `json:"keys"`
	Values      []string           `json:"values"`
}

func (q *Queries) CountWorkflowRuns(ctx context.Context, db DBTX, arg CountWorkflowRunsParams) (int64, error) {
	row := db.QueryRow(ctx, countWorkflowRuns,
		arg.Tenantid,
		arg.WorkflowIds,
		arg.Statuses,
		arg.Since,
		arg.Until,
		arg.Keys,
		arg.Values,
	)
	var count int64
	err := row.Scan(&count)
	return count, err
}

type CreateDAGsOLAPParams struct {
	TenantID           pgtype.UUID        `json:"tenant_id"`
	ID                 int64              `json:"id"`
	InsertedAt         pgtype.Timestamptz `json:"inserted_at"`
	ExternalID         pgtype.UUID        `json:"external_id"`
	DisplayName        string             `json:"display_name"`
	WorkflowID         pgtype.UUID        `json:"workflow_id"`
	WorkflowVersionID  pgtype.UUID        `json:"workflow_version_id"`
	Input              []byte             `json:"input"`
	AdditionalMetadata []byte             `json:"additional_metadata"`
}

const createOLAPDAGPartition = `-- name: CreateOLAPDAGPartition :exec
SELECT create_v2_olap_partition_with_date_and_status(
    'v2_dags_olap'::text,
    $1::date
)
`

func (q *Queries) CreateOLAPDAGPartition(ctx context.Context, db DBTX, date pgtype.Date) error {
	_, err := db.Exec(ctx, createOLAPDAGPartition, date)
	return err
}

const createOLAPRunsPartition = `-- name: CreateOLAPRunsPartition :exec
SELECT create_v2_olap_partition_with_date_and_status(
    'v2_runs_olap'::text,
    $1::date
)
`

func (q *Queries) CreateOLAPRunsPartition(ctx context.Context, db DBTX, date pgtype.Date) error {
	_, err := db.Exec(ctx, createOLAPRunsPartition, date)
	return err
}

const createOLAPTaskEventTmpPartitions = `-- name: CreateOLAPTaskEventTmpPartitions :exec
SELECT create_v2_hash_partitions(
    'v2_task_events_olap_tmp'::text,
    $1::int
)
`

func (q *Queries) CreateOLAPTaskEventTmpPartitions(ctx context.Context, db DBTX, partitions int32) error {
	_, err := db.Exec(ctx, createOLAPTaskEventTmpPartitions, partitions)
	return err
}

const createOLAPTaskPartition = `-- name: CreateOLAPTaskPartition :exec
SELECT create_v2_olap_partition_with_date_and_status(
    'v2_tasks_olap'::text,
    $1::date
)
`

func (q *Queries) CreateOLAPTaskPartition(ctx context.Context, db DBTX, date pgtype.Date) error {
	_, err := db.Exec(ctx, createOLAPTaskPartition, date)
	return err
}

const createOLAPTaskStatusUpdateTmpPartitions = `-- name: CreateOLAPTaskStatusUpdateTmpPartitions :exec
SELECT create_v2_hash_partitions(
    'v2_task_status_updates_tmp'::text,
    $1::int
)
`

func (q *Queries) CreateOLAPTaskStatusUpdateTmpPartitions(ctx context.Context, db DBTX, partitions int32) error {
	_, err := db.Exec(ctx, createOLAPTaskStatusUpdateTmpPartitions, partitions)
	return err
}

type CreateTaskEventsOLAPParams struct {
	TenantID               pgtype.UUID          `json:"tenant_id"`
	TaskID                 int64                `json:"task_id"`
	TaskInsertedAt         pgtype.Timestamptz   `json:"task_inserted_at"`
	EventType              V2EventTypeOlap      `json:"event_type"`
	WorkflowID             pgtype.UUID          `json:"workflow_id"`
	EventTimestamp         pgtype.Timestamptz   `json:"event_timestamp"`
	ReadableStatus         V2ReadableStatusOlap `json:"readable_status"`
	RetryCount             int32                `json:"retry_count"`
	ErrorMessage           pgtype.Text          `json:"error_message"`
	Output                 []byte               `json:"output"`
	WorkerID               pgtype.UUID          `json:"worker_id"`
	AdditionalEventData    pgtype.Text          `json:"additional__event_data"`
	AdditionalEventMessage pgtype.Text          `json:"additional__event_message"`
}

type CreateTaskEventsOLAPTmpParams struct {
	TenantID       pgtype.UUID          `json:"tenant_id"`
	TaskID         int64                `json:"task_id"`
	TaskInsertedAt pgtype.Timestamptz   `json:"task_inserted_at"`
	EventType      V2EventTypeOlap      `json:"event_type"`
	ReadableStatus V2ReadableStatusOlap `json:"readable_status"`
	RetryCount     int32                `json:"retry_count"`
	WorkerID       pgtype.UUID          `json:"worker_id"`
}

type CreateTasksOLAPParams struct {
	TenantID           pgtype.UUID          `json:"tenant_id"`
	ID                 int64                `json:"id"`
	InsertedAt         pgtype.Timestamptz   `json:"inserted_at"`
	Queue              string               `json:"queue"`
	ActionID           string               `json:"action_id"`
	StepID             pgtype.UUID          `json:"step_id"`
	WorkflowID         pgtype.UUID          `json:"workflow_id"`
	ScheduleTimeout    string               `json:"schedule_timeout"`
	StepTimeout        pgtype.Text          `json:"step_timeout"`
	Priority           pgtype.Int4          `json:"priority"`
	Sticky             V2StickyStrategyOlap `json:"sticky"`
	DesiredWorkerID    pgtype.UUID          `json:"desired_worker_id"`
	ExternalID         pgtype.UUID          `json:"external_id"`
	DisplayName        string               `json:"display_name"`
	Input              []byte               `json:"input"`
	AdditionalMetadata []byte               `json:"additional_metadata"`
	DagID              pgtype.Int8          `json:"dag_id"`
	DagInsertedAt      pgtype.Timestamptz   `json:"dag_inserted_at"`
}

const fetchWorkflowRunIds = `-- name: FetchWorkflowRunIds :many
SELECT id, inserted_at, kind, external_id
FROM v2_runs_olap
WHERE
    tenant_id = $1::uuid
    AND (
        $2::uuid[] IS NULL
        OR workflow_id = ANY($2::uuid[])
    )
    AND (
        $3::text[] IS NULL
        OR readable_status = ANY(cast($3::text[] as v2_readable_status_olap[]))
    )
    AND inserted_at >= $4::timestamptz
    AND (
        $5::timestamptz IS NULL
        OR inserted_at <= $5::timestamptz
    )
    AND (
        $6::text[] IS NULL
        OR $7::text[] IS NULL
        OR EXISTS (
            SELECT 1 FROM jsonb_each_text(additional_metadata) kv
            JOIN LATERAL (
                SELECT unnest($6::text[]) AS k,
                    unnest($7::text[]) AS v
            ) AS u ON kv.key = u.k AND kv.value = u.v
        )
    )
ORDER BY inserted_at DESC, id DESC
LIMIT $9::integer
OFFSET $8::integer
`

type FetchWorkflowRunIdsParams struct {
	Tenantid               pgtype.UUID        `json:"tenantid"`
	WorkflowIds            []pgtype.UUID      `json:"workflowIds"`
	Statuses               []string           `json:"statuses"`
	Since                  pgtype.Timestamptz `json:"since"`
	Until                  pgtype.Timestamptz `json:"until"`
	Keys                   []string           `json:"keys"`
	Values                 []string           `json:"values"`
	Listworkflowrunsoffset int32              `json:"listworkflowrunsoffset"`
	Listworkflowrunslimit  int32              `json:"listworkflowrunslimit"`
}

type FetchWorkflowRunIdsRow struct {
	ID         int64              `json:"id"`
	InsertedAt pgtype.Timestamptz `json:"inserted_at"`
	Kind       V2RunKind          `json:"kind"`
	ExternalID pgtype.UUID        `json:"external_id"`
}

func (q *Queries) FetchWorkflowRunIds(ctx context.Context, db DBTX, arg FetchWorkflowRunIdsParams) ([]*FetchWorkflowRunIdsRow, error) {
	rows, err := db.Query(ctx, fetchWorkflowRunIds,
		arg.Tenantid,
		arg.WorkflowIds,
		arg.Statuses,
		arg.Since,
		arg.Until,
		arg.Keys,
		arg.Values,
		arg.Listworkflowrunsoffset,
		arg.Listworkflowrunslimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*FetchWorkflowRunIdsRow
	for rows.Next() {
		var i FetchWorkflowRunIdsRow
		if err := rows.Scan(
			&i.ID,
			&i.InsertedAt,
			&i.Kind,
			&i.ExternalID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTaskPointMetrics = `-- name: GetTaskPointMetrics :many
SELECT
    time_bucket(COALESCE($1::interval, '1 minute'), bucket)::timestamptz as bucket_2,
    SUM(completed_count)::int as completed_count,
    SUM(failed_count)::int as failed_count
FROM
    v2_cagg_task_events_minute
WHERE
    tenant_id = $2::uuid AND
    -- timestamptz makes this fast, apparently:
    -- https://www.timescale.com/forum/t/very-slow-query-planning-time-in-postgresql/255/8
    bucket >= time_bucket('1 minute', $3::timestamptz) AND
    bucket <= time_bucket('1 minute', $4::timestamptz)
GROUP BY bucket_2
ORDER BY bucket_2
`

type GetTaskPointMetricsParams struct {
	Interval      pgtype.Interval    `json:"interval"`
	Tenantid      pgtype.UUID        `json:"tenantid"`
	Createdafter  pgtype.Timestamptz `json:"createdafter"`
	Createdbefore pgtype.Timestamptz `json:"createdbefore"`
}

type GetTaskPointMetricsRow struct {
	Bucket2        pgtype.Timestamptz `json:"bucket_2"`
	CompletedCount int32              `json:"completed_count"`
	FailedCount    int32              `json:"failed_count"`
}

func (q *Queries) GetTaskPointMetrics(ctx context.Context, db DBTX, arg GetTaskPointMetricsParams) ([]*GetTaskPointMetricsRow, error) {
	rows, err := db.Query(ctx, getTaskPointMetrics,
		arg.Interval,
		arg.Tenantid,
		arg.Createdafter,
		arg.Createdbefore,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*GetTaskPointMetricsRow
	for rows.Next() {
		var i GetTaskPointMetricsRow
		if err := rows.Scan(&i.Bucket2, &i.CompletedCount, &i.FailedCount); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTenantStatusMetrics = `-- name: GetTenantStatusMetrics :one
SELECT
  COALESCE(SUM(queued_count), 0)::bigint AS total_queued,
  COALESCE(SUM(running_count), 0)::bigint AS total_running,
  COALESCE(SUM(completed_count), 0)::bigint AS total_completed,
  COALESCE(SUM(cancelled_count), 0)::bigint AS total_cancelled,
  COALESCE(SUM(failed_count), 0)::bigint AS total_failed
FROM v2_cagg_status_metrics
WHERE
    tenant_id = $1::uuid
    AND bucket >= time_bucket('5 minutes', $2::timestamptz)
    AND (
        $3::uuid[] IS NULL OR workflow_id = ANY($3::uuid[])
    )
`

type GetTenantStatusMetricsParams struct {
	Tenantid     pgtype.UUID        `json:"tenantid"`
	Createdafter pgtype.Timestamptz `json:"createdafter"`
	WorkflowIds  []pgtype.UUID      `json:"workflowIds"`
}

type GetTenantStatusMetricsRow struct {
	TotalQueued    int64 `json:"total_queued"`
	TotalRunning   int64 `json:"total_running"`
	TotalCompleted int64 `json:"total_completed"`
	TotalCancelled int64 `json:"total_cancelled"`
	TotalFailed    int64 `json:"total_failed"`
}

func (q *Queries) GetTenantStatusMetrics(ctx context.Context, db DBTX, arg GetTenantStatusMetricsParams) (*GetTenantStatusMetricsRow, error) {
	row := db.QueryRow(ctx, getTenantStatusMetrics, arg.Tenantid, arg.Createdafter, arg.WorkflowIds)
	var i GetTenantStatusMetricsRow
	err := row.Scan(
		&i.TotalQueued,
		&i.TotalRunning,
		&i.TotalCompleted,
		&i.TotalCancelled,
		&i.TotalFailed,
	)
	return &i, err
}

const listOLAPDAGPartitionsBeforeDate = `-- name: ListOLAPDAGPartitionsBeforeDate :many
SELECT
    p::text AS partition_name
FROM
    get_v2_partitions_before_date(
        'v2_dags_olap'::text,
        $1::date
    ) AS p
`

func (q *Queries) ListOLAPDAGPartitionsBeforeDate(ctx context.Context, db DBTX, date pgtype.Date) ([]string, error) {
	rows, err := db.Query(ctx, listOLAPDAGPartitionsBeforeDate, date)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var partition_name string
		if err := rows.Scan(&partition_name); err != nil {
			return nil, err
		}
		items = append(items, partition_name)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listOLAPRunsPartitionsBeforeDate = `-- name: ListOLAPRunsPartitionsBeforeDate :many
SELECT
    p::text AS partition_name
FROM
    get_v2_partitions_before_date(
        'v2_runs_olap'::text,
        $1::date
    ) AS p
`

func (q *Queries) ListOLAPRunsPartitionsBeforeDate(ctx context.Context, db DBTX, date pgtype.Date) ([]string, error) {
	rows, err := db.Query(ctx, listOLAPRunsPartitionsBeforeDate, date)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var partition_name string
		if err := rows.Scan(&partition_name); err != nil {
			return nil, err
		}
		items = append(items, partition_name)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listOLAPTaskPartitionsBeforeDate = `-- name: ListOLAPTaskPartitionsBeforeDate :many
SELECT
    p::text AS partition_name
FROM
    get_v2_partitions_before_date(
        'v2_tasks_olap'::text,
        $1::date
    ) AS p
`

func (q *Queries) ListOLAPTaskPartitionsBeforeDate(ctx context.Context, db DBTX, date pgtype.Date) ([]string, error) {
	rows, err := db.Query(ctx, listOLAPTaskPartitionsBeforeDate, date)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var partition_name string
		if err := rows.Scan(&partition_name); err != nil {
			return nil, err
		}
		items = append(items, partition_name)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listTaskEvents = `-- name: ListTaskEvents :many
WITH aggregated_events AS (
  SELECT
    tenant_id,
    task_id,
    task_inserted_at,
    retry_count,
    event_type,
    MIN(event_timestamp) AS time_first_seen,
    MAX(event_timestamp) AS time_last_seen,
    COUNT(*) AS count,
    MIN(id) AS first_id
  FROM v2_task_events_olap
  WHERE
    tenant_id = $1::uuid
    AND task_id = $2::bigint
    AND task_inserted_at = $3::timestamptz
  GROUP BY tenant_id, task_id, task_inserted_at, retry_count, event_type
)
SELECT
  a.tenant_id,
  a.task_id,
  a.task_inserted_at,
  a.retry_count,
  a.event_type,
  a.time_first_seen,
  a.time_last_seen,
  a.count,
  t.id,
  t.event_timestamp,
  t.readable_status,
  t.error_message,
  t.output,
  t.worker_id,
  t.additional__event_data,
  t.additional__event_message
FROM aggregated_events a
JOIN v2_task_events_olap t
  ON t.tenant_id = a.tenant_id
  AND t.task_id = a.task_id
  AND t.task_inserted_at = a.task_inserted_at
  AND t.id = a.first_id
ORDER BY a.time_first_seen DESC, t.event_timestamp DESC
`

type ListTaskEventsParams struct {
	Tenantid       pgtype.UUID        `json:"tenantid"`
	Taskid         int64              `json:"taskid"`
	Taskinsertedat pgtype.Timestamptz `json:"taskinsertedat"`
}

type ListTaskEventsRow struct {
	TenantID               pgtype.UUID          `json:"tenant_id"`
	TaskID                 int64                `json:"task_id"`
	TaskInsertedAt         pgtype.Timestamptz   `json:"task_inserted_at"`
	RetryCount             int32                `json:"retry_count"`
	EventType              V2EventTypeOlap      `json:"event_type"`
	TimeFirstSeen          interface{}          `json:"time_first_seen"`
	TimeLastSeen           interface{}          `json:"time_last_seen"`
	Count                  int64                `json:"count"`
	ID                     int64                `json:"id"`
	EventTimestamp         pgtype.Timestamptz   `json:"event_timestamp"`
	ReadableStatus         V2ReadableStatusOlap `json:"readable_status"`
	ErrorMessage           pgtype.Text          `json:"error_message"`
	Output                 []byte               `json:"output"`
	WorkerID               pgtype.UUID          `json:"worker_id"`
	AdditionalEventData    pgtype.Text          `json:"additional__event_data"`
	AdditionalEventMessage pgtype.Text          `json:"additional__event_message"`
}

func (q *Queries) ListTaskEvents(ctx context.Context, db DBTX, arg ListTaskEventsParams) ([]*ListTaskEventsRow, error) {
	rows, err := db.Query(ctx, listTaskEvents, arg.Tenantid, arg.Taskid, arg.Taskinsertedat)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*ListTaskEventsRow
	for rows.Next() {
		var i ListTaskEventsRow
		if err := rows.Scan(
			&i.TenantID,
			&i.TaskID,
			&i.TaskInsertedAt,
			&i.RetryCount,
			&i.EventType,
			&i.TimeFirstSeen,
			&i.TimeLastSeen,
			&i.Count,
			&i.ID,
			&i.EventTimestamp,
			&i.ReadableStatus,
			&i.ErrorMessage,
			&i.Output,
			&i.WorkerID,
			&i.AdditionalEventData,
			&i.AdditionalEventMessage,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listTasks = `-- name: ListTasks :many
SELECT
    id,
    inserted_at
FROM
    v2_tasks_olap
WHERE
    tenant_id = $1::uuid
    AND inserted_at >= $2::timestamptz
    AND (
        $3::timestamptz IS NULL
        OR inserted_at <= $3::timestamptz
    )
    AND (
        $4::text[] IS NULL OR readable_status = ANY(cast($4::text[] as v2_readable_status_olap[]))
    )
    AND (
        $5::uuid[] IS NULL OR workflow_id = ANY($5::uuid[])
    )
    AND (
        $6::uuid IS NULL OR latest_worker_id = $6::uuid
    )
    AND (
        $7::text[] IS NULL
        OR $8::text[] IS NULL
        OR EXISTS (
            SELECT 1 FROM jsonb_each_text(additional_metadata) kv
            JOIN LATERAL (
                SELECT unnest($7::text[]) AS k,
                    unnest($8::text[]) AS v
            ) AS u ON kv.key = u.k AND kv.value = u.v
        )
    )
ORDER BY
    inserted_at DESC
LIMIT $10::integer
OFFSET $9::integer
`

type ListTasksParams struct {
	Tenantid    pgtype.UUID        `json:"tenantid"`
	Since       pgtype.Timestamptz `json:"since"`
	Until       pgtype.Timestamptz `json:"until"`
	Statuses    []string           `json:"statuses"`
	WorkflowIds []pgtype.UUID      `json:"workflowIds"`
	WorkerId    pgtype.UUID        `json:"workerId"`
	Keys        []string           `json:"keys"`
	Values      []string           `json:"values"`
	Taskoffset  int32              `json:"taskoffset"`
	Tasklimit   int32              `json:"tasklimit"`
}

type ListTasksRow struct {
	ID         int64              `json:"id"`
	InsertedAt pgtype.Timestamptz `json:"inserted_at"`
}

func (q *Queries) ListTasks(ctx context.Context, db DBTX, arg ListTasksParams) ([]*ListTasksRow, error) {
	rows, err := db.Query(ctx, listTasks,
		arg.Tenantid,
		arg.Since,
		arg.Until,
		arg.Statuses,
		arg.WorkflowIds,
		arg.WorkerId,
		arg.Keys,
		arg.Values,
		arg.Taskoffset,
		arg.Tasklimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*ListTasksRow
	for rows.Next() {
		var i ListTasksRow
		if err := rows.Scan(&i.ID, &i.InsertedAt); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listTasksByDAGIds = `-- name: ListTasksByDAGIds :many
SELECT
    dt.dag_id, dt.dag_inserted_at, dt.task_id, dt.task_inserted_at,
    lt.external_id AS dag_external_id
FROM
    v2_lookup_table lt
JOIN
    v2_dag_to_task_olap dt ON lt.dag_id = dt.dag_id
WHERE
    lt.external_id = ANY($1::uuid[])
    AND tenant_id = $2::uuid
`

type ListTasksByDAGIdsParams struct {
	Dagids   []pgtype.UUID `json:"dagids"`
	Tenantid pgtype.UUID   `json:"tenantid"`
}

type ListTasksByDAGIdsRow struct {
	DagID          int64              `json:"dag_id"`
	DagInsertedAt  pgtype.Timestamptz `json:"dag_inserted_at"`
	TaskID         int64              `json:"task_id"`
	TaskInsertedAt pgtype.Timestamptz `json:"task_inserted_at"`
	DagExternalID  pgtype.UUID        `json:"dag_external_id"`
}

func (q *Queries) ListTasksByDAGIds(ctx context.Context, db DBTX, arg ListTasksByDAGIdsParams) ([]*ListTasksByDAGIdsRow, error) {
	rows, err := db.Query(ctx, listTasksByDAGIds, arg.Dagids, arg.Tenantid)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*ListTasksByDAGIdsRow
	for rows.Next() {
		var i ListTasksByDAGIdsRow
		if err := rows.Scan(
			&i.DagID,
			&i.DagInsertedAt,
			&i.TaskID,
			&i.TaskInsertedAt,
			&i.DagExternalID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listTasksByExternalIds = `-- name: ListTasksByExternalIds :many
SELECT
    tenant_id,
    task_id,
    inserted_at
FROM
    v2_lookup_table
WHERE
    external_id = ANY($1::uuid[])
    AND tenant_id = $2::uuid
`

type ListTasksByExternalIdsParams struct {
	Externalids []pgtype.UUID `json:"externalids"`
	Tenantid    pgtype.UUID   `json:"tenantid"`
}

type ListTasksByExternalIdsRow struct {
	TenantID   pgtype.UUID        `json:"tenant_id"`
	TaskID     pgtype.Int8        `json:"task_id"`
	InsertedAt pgtype.Timestamptz `json:"inserted_at"`
}

func (q *Queries) ListTasksByExternalIds(ctx context.Context, db DBTX, arg ListTasksByExternalIdsParams) ([]*ListTasksByExternalIdsRow, error) {
	rows, err := db.Query(ctx, listTasksByExternalIds, arg.Externalids, arg.Tenantid)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*ListTasksByExternalIdsRow
	for rows.Next() {
		var i ListTasksByExternalIdsRow
		if err := rows.Scan(&i.TenantID, &i.TaskID, &i.InsertedAt); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const populateDAGMetadata = `-- name: PopulateDAGMetadata :many
WITH input AS (
    SELECT
        UNNEST($1::bigint[]) AS id,
        UNNEST($2::timestamptz[]) AS inserted_at
), runs AS (
    SELECT
        d.id AS dag_id,
        r.id AS run_id,
        r.tenant_id,
        r.inserted_at,
        r.external_id,
        r.readable_status,
        r.kind,
        r.workflow_id,
        d.display_name,
        d.input,
        d.additional_metadata
    FROM v2_runs_olap r
    JOIN v2_dags_olap d ON (r.tenant_id, r.external_id, r.inserted_at) = (d.tenant_id, d.external_id, d.inserted_at)
    WHERE
        (r.inserted_at, r.id) IN (SELECT inserted_at, id FROM input)
        AND r.tenant_id = $3::uuid
        AND r.kind = 'DAG'
), relevant_events AS (
    SELECT
        r.run_id,
        e.tenant_id, e.id, e.inserted_at, e.task_id, e.task_inserted_at, e.event_type, e.workflow_id, e.event_timestamp, e.readable_status, e.retry_count, e.error_message, e.output, e.worker_id, e.additional__event_data, e.additional__event_message
    FROM runs r
    JOIN v2_dag_to_task_olap dt ON r.dag_id = dt.dag_id  -- Do I need to join by ` + "`" + `inserted_at` + "`" + ` here too?
    JOIN v2_task_events_olap e ON e.task_id = dt.task_id -- Do I need to join by ` + "`" + `inserted_at` + "`" + ` here too?
), metadata AS (
    SELECT
        e.run_id,
        MIN(e.inserted_at)::timestamptz AS created_at,
        MIN(e.inserted_at) FILTER (WHERE e.readable_status = 'RUNNING')::timestamptz AS started_at,
        MAX(e.inserted_at) FILTER (WHERE e.readable_status IN ('COMPLETED', 'CANCELLED', 'FAILED'))::timestamptz AS finished_at
    FROM
        relevant_events e
    GROUP BY e.run_id
), error_message AS (
    SELECT
        DISTINCT ON (e.run_id) e.run_id::bigint,
        e.error_message
    FROM
        relevant_events e
    WHERE
        e.readable_status = 'FAILED'
    ORDER BY
        e.run_id, e.retry_count DESC
)
SELECT
    r.dag_id, r.run_id, r.tenant_id, r.inserted_at, r.external_id, r.readable_status, r.kind, r.workflow_id, r.display_name, r.input, r.additional_metadata,
    m.created_at,
    m.started_at,
    m.finished_at,
    e.error_message
FROM runs r
LEFT JOIN metadata m ON r.run_id = m.run_id
LEFT JOIN error_message e ON r.run_id = e.run_id
ORDER BY r.inserted_at DESC, r.run_id DESC
`

type PopulateDAGMetadataParams struct {
	Ids         []int64              `json:"ids"`
	Insertedats []pgtype.Timestamptz `json:"insertedats"`
	Tenantid    pgtype.UUID          `json:"tenantid"`
}

type PopulateDAGMetadataRow struct {
	DagID              int64                `json:"dag_id"`
	RunID              int64                `json:"run_id"`
	TenantID           pgtype.UUID          `json:"tenant_id"`
	InsertedAt         pgtype.Timestamptz   `json:"inserted_at"`
	ExternalID         pgtype.UUID          `json:"external_id"`
	ReadableStatus     V2ReadableStatusOlap `json:"readable_status"`
	Kind               V2RunKind            `json:"kind"`
	WorkflowID         pgtype.UUID          `json:"workflow_id"`
	DisplayName        string               `json:"display_name"`
	Input              []byte               `json:"input"`
	AdditionalMetadata []byte               `json:"additional_metadata"`
	CreatedAt          pgtype.Timestamptz   `json:"created_at"`
	StartedAt          pgtype.Timestamptz   `json:"started_at"`
	FinishedAt         pgtype.Timestamptz   `json:"finished_at"`
	ErrorMessage       pgtype.Text          `json:"error_message"`
}

func (q *Queries) PopulateDAGMetadata(ctx context.Context, db DBTX, arg PopulateDAGMetadataParams) ([]*PopulateDAGMetadataRow, error) {
	rows, err := db.Query(ctx, populateDAGMetadata, arg.Ids, arg.Insertedats, arg.Tenantid)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*PopulateDAGMetadataRow
	for rows.Next() {
		var i PopulateDAGMetadataRow
		if err := rows.Scan(
			&i.DagID,
			&i.RunID,
			&i.TenantID,
			&i.InsertedAt,
			&i.ExternalID,
			&i.ReadableStatus,
			&i.Kind,
			&i.WorkflowID,
			&i.DisplayName,
			&i.Input,
			&i.AdditionalMetadata,
			&i.CreatedAt,
			&i.StartedAt,
			&i.FinishedAt,
			&i.ErrorMessage,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const populateSingleTaskRunData = `-- name: PopulateSingleTaskRunData :one
WITH latest_retry_count AS (
    SELECT
        MAX(retry_count) AS retry_count
    FROM
        v2_task_events_olap
    WHERE
        tenant_id = $1::uuid
        AND task_id = $2::bigint
        AND task_inserted_at = $3::timestamptz
), relevant_events AS (
    SELECT
        tenant_id, id, inserted_at, task_id, task_inserted_at, event_type, workflow_id, event_timestamp, readable_status, retry_count, error_message, output, worker_id, additional__event_data, additional__event_message
    FROM
        v2_task_events_olap
    WHERE
        tenant_id = $1::uuid
        AND task_id = $2::bigint
        AND task_inserted_at = $3::timestamptz
        AND retry_count = (SELECT retry_count FROM latest_retry_count)
    ORDER BY
        event_timestamp DESC
), finished_at AS (
    SELECT
        MAX(event_timestamp) AS finished_at
    FROM
        relevant_events
    WHERE
        readable_status = ANY(ARRAY['COMPLETED', 'FAILED', 'CANCELLED']::v2_readable_status_olap[])
), started_at AS (
    SELECT
        MAX(event_timestamp) AS started_at
    FROM
        relevant_events
    WHERE
        event_type = 'STARTED'
), task_output AS (
    SELECT
        output
    FROM
        relevant_events
    WHERE
        event_type = 'FINISHED'
), status AS (
    SELECT
        readable_status
    FROM
        relevant_events
    ORDER BY
        readable_status DESC
    LIMIT 1
), error_message AS (
    SELECT
        error_message
    FROM
        relevant_events
    WHERE
        readable_status = 'FAILED'
    ORDER BY
        event_timestamp DESC
    LIMIT 1
)
SELECT
    t.tenant_id, t.id, t.inserted_at, t.external_id, t.queue, t.action_id, t.step_id, t.workflow_id, t.schedule_timeout, t.step_timeout, t.priority, t.sticky, t.desired_worker_id, t.display_name, t.input, t.additional_metadata, t.readable_status, t.latest_retry_count, t.latest_worker_id, t.dag_id, t.dag_inserted_at,
    st.readable_status::v2_readable_status_olap as status,
    f.finished_at::timestamptz as finished_at,
    s.started_at::timestamptz as started_at,
    o.output::jsonb as output,
    e.error_message as error_message
FROM
    v2_tasks_olap t
LEFT JOIN
    finished_at f ON true
LEFT JOIN
    started_at s ON true
LEFT JOIN
    task_output o ON true
LEFT JOIN
    status st ON true
LEFT JOIN
    error_message e ON true
WHERE
    (t.tenant_id, t.id, t.inserted_at) = ($1::uuid, $2::bigint, $3::timestamptz)
`

type PopulateSingleTaskRunDataParams struct {
	Tenantid       pgtype.UUID        `json:"tenantid"`
	Taskid         int64              `json:"taskid"`
	Taskinsertedat pgtype.Timestamptz `json:"taskinsertedat"`
}

type PopulateSingleTaskRunDataRow struct {
	TenantID           pgtype.UUID          `json:"tenant_id"`
	ID                 int64                `json:"id"`
	InsertedAt         pgtype.Timestamptz   `json:"inserted_at"`
	ExternalID         pgtype.UUID          `json:"external_id"`
	Queue              string               `json:"queue"`
	ActionID           string               `json:"action_id"`
	StepID             pgtype.UUID          `json:"step_id"`
	WorkflowID         pgtype.UUID          `json:"workflow_id"`
	ScheduleTimeout    string               `json:"schedule_timeout"`
	StepTimeout        pgtype.Text          `json:"step_timeout"`
	Priority           pgtype.Int4          `json:"priority"`
	Sticky             V2StickyStrategyOlap `json:"sticky"`
	DesiredWorkerID    pgtype.UUID          `json:"desired_worker_id"`
	DisplayName        string               `json:"display_name"`
	Input              []byte               `json:"input"`
	AdditionalMetadata []byte               `json:"additional_metadata"`
	ReadableStatus     V2ReadableStatusOlap `json:"readable_status"`
	LatestRetryCount   int32                `json:"latest_retry_count"`
	LatestWorkerID     pgtype.UUID          `json:"latest_worker_id"`
	DagID              pgtype.Int8          `json:"dag_id"`
	DagInsertedAt      pgtype.Timestamptz   `json:"dag_inserted_at"`
	Status             V2ReadableStatusOlap `json:"status"`
	FinishedAt         pgtype.Timestamptz   `json:"finished_at"`
	StartedAt          pgtype.Timestamptz   `json:"started_at"`
	Output             []byte               `json:"output"`
	ErrorMessage       pgtype.Text          `json:"error_message"`
}

func (q *Queries) PopulateSingleTaskRunData(ctx context.Context, db DBTX, arg PopulateSingleTaskRunDataParams) (*PopulateSingleTaskRunDataRow, error) {
	row := db.QueryRow(ctx, populateSingleTaskRunData, arg.Tenantid, arg.Taskid, arg.Taskinsertedat)
	var i PopulateSingleTaskRunDataRow
	err := row.Scan(
		&i.TenantID,
		&i.ID,
		&i.InsertedAt,
		&i.ExternalID,
		&i.Queue,
		&i.ActionID,
		&i.StepID,
		&i.WorkflowID,
		&i.ScheduleTimeout,
		&i.StepTimeout,
		&i.Priority,
		&i.Sticky,
		&i.DesiredWorkerID,
		&i.DisplayName,
		&i.Input,
		&i.AdditionalMetadata,
		&i.ReadableStatus,
		&i.LatestRetryCount,
		&i.LatestWorkerID,
		&i.DagID,
		&i.DagInsertedAt,
		&i.Status,
		&i.FinishedAt,
		&i.StartedAt,
		&i.Output,
		&i.ErrorMessage,
	)
	return &i, err
}

const populateTaskRunData = `-- name: PopulateTaskRunData :many
WITH input AS (
    SELECT
        UNNEST($1::bigint[]) AS id,
        UNNEST($2::timestamptz[]) AS inserted_at
), tasks AS (
    SELECT
        DISTINCT ON(t.tenant_id, t.id, t.inserted_at)
        t.tenant_id,
        t.id,
        t.inserted_at,
        t.queue,
        t.action_id,
        t.step_id,
        t.workflow_id,
        t.schedule_timeout,
        t.step_timeout,
        t.priority,
        t.sticky,
        t.desired_worker_id,
        t.external_id,
        t.display_name,
        t.input,
        t.additional_metadata,
        t.readable_status
    FROM
        v2_tasks_olap t
    JOIN
        input i ON i.id = t.id AND i.inserted_at = t.inserted_at
    WHERE
        t.tenant_id = $3::uuid
), relevant_events AS (
    SELECT
        e.tenant_id, e.id, e.inserted_at, e.task_id, e.task_inserted_at, e.event_type, e.workflow_id, e.event_timestamp, e.readable_status, e.retry_count, e.error_message, e.output, e.worker_id, e.additional__event_data, e.additional__event_message
    FROM
        v2_task_events_olap e
    JOIN
        tasks t ON t.id = e.task_id AND t.tenant_id = e.tenant_id AND t.inserted_at = e.task_inserted_at
), max_retry_counts AS (
    SELECT
        e.tenant_id,
        e.task_id,
        e.task_inserted_at,
        MAX(e.retry_count) AS max_retry_count
    FROM
        relevant_events e
    GROUP BY
        e.tenant_id, e.task_id, e.task_inserted_at
), finished_ats AS (
    SELECT
        e.task_id::bigint,
        MAX(e.event_timestamp) AS finished_at
    FROM
        relevant_events e
    JOIN
        max_retry_counts mrc ON
            e.tenant_id = mrc.tenant_id
            AND e.task_id = mrc.task_id
            AND e.task_inserted_at = mrc.task_inserted_at
            AND e.retry_count = mrc.max_retry_count
    WHERE
        e.readable_status = ANY(ARRAY['COMPLETED', 'FAILED', 'CANCELLED']::v2_readable_status_olap[])
    GROUP BY e.task_id
), started_ats AS (
    SELECT
        e.task_id::bigint,
        MAX(e.event_timestamp) AS started_at
    FROM
        relevant_events e
    JOIN
        max_retry_counts mrc ON
            e.tenant_id = mrc.tenant_id
            AND e.task_id = mrc.task_id
            AND e.task_inserted_at = mrc.task_inserted_at
            AND e.retry_count = mrc.max_retry_count
    WHERE
        e.event_type = 'STARTED'
    GROUP BY e.task_id
), error_message AS (
    SELECT
        DISTINCT ON (e.task_id) e.task_id::bigint,
        e.error_message
    FROM
        relevant_events e
    JOIN
        max_retry_counts mrc ON
            e.tenant_id = mrc.tenant_id
            AND e.task_id = mrc.task_id
            AND e.task_inserted_at = mrc.task_inserted_at
            AND e.retry_count = mrc.max_retry_count
    WHERE
        e.readable_status = 'FAILED'
    ORDER BY
        e.task_id, e.retry_count DESC
)
SELECT
    t.tenant_id,
    t.id,
    t.inserted_at,
    t.external_id,
    t.queue,
    t.action_id,
    t.step_id,
    t.workflow_id,
    t.schedule_timeout,
    t.step_timeout,
    t.priority,
    t.sticky,
    t.display_name,
    t.additional_metadata,
    t.readable_status::v2_readable_status_olap as status,
    f.finished_at::timestamptz as finished_at,
    s.started_at::timestamptz as started_at,
    e.error_message as error_message
FROM
    tasks t
LEFT JOIN
    finished_ats f ON f.task_id = t.id
LEFT JOIN
    started_ats s ON s.task_id = t.id
LEFT JOIN
    error_message e ON e.task_id = t.id
ORDER BY t.inserted_at DESC, t.id DESC
`

type PopulateTaskRunDataParams struct {
	Taskids         []int64              `json:"taskids"`
	Taskinsertedats []pgtype.Timestamptz `json:"taskinsertedats"`
	Tenantid        pgtype.UUID          `json:"tenantid"`
}

type PopulateTaskRunDataRow struct {
	TenantID           pgtype.UUID          `json:"tenant_id"`
	ID                 int64                `json:"id"`
	InsertedAt         pgtype.Timestamptz   `json:"inserted_at"`
	ExternalID         pgtype.UUID          `json:"external_id"`
	Queue              string               `json:"queue"`
	ActionID           string               `json:"action_id"`
	StepID             pgtype.UUID          `json:"step_id"`
	WorkflowID         pgtype.UUID          `json:"workflow_id"`
	ScheduleTimeout    string               `json:"schedule_timeout"`
	StepTimeout        pgtype.Text          `json:"step_timeout"`
	Priority           pgtype.Int4          `json:"priority"`
	Sticky             V2StickyStrategyOlap `json:"sticky"`
	DisplayName        string               `json:"display_name"`
	AdditionalMetadata []byte               `json:"additional_metadata"`
	Status             V2ReadableStatusOlap `json:"status"`
	FinishedAt         pgtype.Timestamptz   `json:"finished_at"`
	StartedAt          pgtype.Timestamptz   `json:"started_at"`
	ErrorMessage       pgtype.Text          `json:"error_message"`
}

func (q *Queries) PopulateTaskRunData(ctx context.Context, db DBTX, arg PopulateTaskRunDataParams) ([]*PopulateTaskRunDataRow, error) {
	rows, err := db.Query(ctx, populateTaskRunData, arg.Taskids, arg.Taskinsertedats, arg.Tenantid)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*PopulateTaskRunDataRow
	for rows.Next() {
		var i PopulateTaskRunDataRow
		if err := rows.Scan(
			&i.TenantID,
			&i.ID,
			&i.InsertedAt,
			&i.ExternalID,
			&i.Queue,
			&i.ActionID,
			&i.StepID,
			&i.WorkflowID,
			&i.ScheduleTimeout,
			&i.StepTimeout,
			&i.Priority,
			&i.Sticky,
			&i.DisplayName,
			&i.AdditionalMetadata,
			&i.Status,
			&i.FinishedAt,
			&i.StartedAt,
			&i.ErrorMessage,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const readDAGByExternalID = `-- name: ReadDAGByExternalID :one
WITH lookup_task AS (
    SELECT
        tenant_id,
        dag_id,
        inserted_at
    FROM
        v2_lookup_table
    WHERE
        external_id = $1::uuid
)
SELECT
    d.id, d.inserted_at, d.tenant_id, d.external_id, d.display_name, d.workflow_id, d.workflow_version_id, d.readable_status, d.input, d.additional_metadata
FROM
    v2_dags_olap d
JOIN
    lookup_task lt ON lt.tenant_id = d.tenant_id AND lt.dag_id = d.id AND lt.inserted_at = d.inserted_at
`

func (q *Queries) ReadDAGByExternalID(ctx context.Context, db DBTX, externalid pgtype.UUID) (*V2DagsOlap, error) {
	row := db.QueryRow(ctx, readDAGByExternalID, externalid)
	var i V2DagsOlap
	err := row.Scan(
		&i.ID,
		&i.InsertedAt,
		&i.TenantID,
		&i.ExternalID,
		&i.DisplayName,
		&i.WorkflowID,
		&i.WorkflowVersionID,
		&i.ReadableStatus,
		&i.Input,
		&i.AdditionalMetadata,
	)
	return &i, err
}

const readTaskByExternalID = `-- name: ReadTaskByExternalID :one
WITH lookup_task AS (
    SELECT
        tenant_id,
        task_id,
        inserted_at
    FROM
        v2_lookup_table
    WHERE
        external_id = $1::uuid
)
SELECT
    t.tenant_id, t.id, t.inserted_at, t.external_id, t.queue, t.action_id, t.step_id, t.workflow_id, t.schedule_timeout, t.step_timeout, t.priority, t.sticky, t.desired_worker_id, t.display_name, t.input, t.additional_metadata, t.readable_status, t.latest_retry_count, t.latest_worker_id, t.dag_id, t.dag_inserted_at,
    e.output,
    e.error_message
FROM
    v2_tasks_olap t
JOIN
    lookup_task lt ON lt.tenant_id = t.tenant_id AND lt.task_id = t.id AND lt.inserted_at = t.inserted_at
JOIN
    v2_task_events_olap e ON (e.tenant_id, e.task_id, e.readable_status, e.retry_count) = (t.tenant_id, t.id, t.readable_status, t.latest_retry_count)
`

type ReadTaskByExternalIDRow struct {
	TenantID           pgtype.UUID          `json:"tenant_id"`
	ID                 int64                `json:"id"`
	InsertedAt         pgtype.Timestamptz   `json:"inserted_at"`
	ExternalID         pgtype.UUID          `json:"external_id"`
	Queue              string               `json:"queue"`
	ActionID           string               `json:"action_id"`
	StepID             pgtype.UUID          `json:"step_id"`
	WorkflowID         pgtype.UUID          `json:"workflow_id"`
	ScheduleTimeout    string               `json:"schedule_timeout"`
	StepTimeout        pgtype.Text          `json:"step_timeout"`
	Priority           pgtype.Int4          `json:"priority"`
	Sticky             V2StickyStrategyOlap `json:"sticky"`
	DesiredWorkerID    pgtype.UUID          `json:"desired_worker_id"`
	DisplayName        string               `json:"display_name"`
	Input              []byte               `json:"input"`
	AdditionalMetadata []byte               `json:"additional_metadata"`
	ReadableStatus     V2ReadableStatusOlap `json:"readable_status"`
	LatestRetryCount   int32                `json:"latest_retry_count"`
	LatestWorkerID     pgtype.UUID          `json:"latest_worker_id"`
	DagID              pgtype.Int8          `json:"dag_id"`
	DagInsertedAt      pgtype.Timestamptz   `json:"dag_inserted_at"`
	Output             []byte               `json:"output"`
	ErrorMessage       pgtype.Text          `json:"error_message"`
}

func (q *Queries) ReadTaskByExternalID(ctx context.Context, db DBTX, externalid pgtype.UUID) (*ReadTaskByExternalIDRow, error) {
	row := db.QueryRow(ctx, readTaskByExternalID, externalid)
	var i ReadTaskByExternalIDRow
	err := row.Scan(
		&i.TenantID,
		&i.ID,
		&i.InsertedAt,
		&i.ExternalID,
		&i.Queue,
		&i.ActionID,
		&i.StepID,
		&i.WorkflowID,
		&i.ScheduleTimeout,
		&i.StepTimeout,
		&i.Priority,
		&i.Sticky,
		&i.DesiredWorkerID,
		&i.DisplayName,
		&i.Input,
		&i.AdditionalMetadata,
		&i.ReadableStatus,
		&i.LatestRetryCount,
		&i.LatestWorkerID,
		&i.DagID,
		&i.DagInsertedAt,
		&i.Output,
		&i.ErrorMessage,
	)
	return &i, err
}

const updateDAGStatuses = `-- name: UpdateDAGStatuses :one
WITH locked_events AS (
    SELECT
        tenant_id, requeue_after, requeue_retries, id, dag_id, dag_inserted_at
    FROM
        list_task_status_updates_tmp(
            $1::int,
            $2::uuid,
            $3::int
        )
), distinct_dags AS (
    SELECT
        DISTINCT ON (e.tenant_id, e.dag_id, e.dag_inserted_at)
        e.tenant_id,
        e.dag_id,
        e.dag_inserted_at
    FROM
        locked_events e
), locked_dags AS (
    SELECT
        d.id,
        d.inserted_at,
        d.readable_status,
        d.tenant_id
    FROM
        v2_dags_olap d
    JOIN
        distinct_dags dd ON
            (d.tenant_id, d.id, d.inserted_at) = (dd.tenant_id, dd.dag_id, dd.dag_inserted_at)
    ORDER BY
        d.id, d.inserted_at
    FOR UPDATE
), dag_task_counts AS (
    SELECT
        d.id,
        d.inserted_at,
        COUNT(t.id) AS task_count,
        COUNT(t.id) FILTER (WHERE t.readable_status = 'COMPLETED') AS completed_count,
        COUNT(t.id) FILTER (WHERE t.readable_status = 'FAILED') AS failed_count,
        COUNT(t.id) FILTER (WHERE t.readable_status = 'CANCELLED') AS cancelled_count,
        COUNT(t.id) FILTER (WHERE t.readable_status = 'QUEUED') AS queued_count,
        COUNT(t.id) FILTER (WHERE t.readable_status = 'RUNNING') AS running_count
    FROM
        locked_dags d
    LEFT JOIN
        v2_dag_to_task_olap dt ON
            (d.id, d.inserted_at) = (dt.dag_id, dt.dag_inserted_at)
    LEFT JOIN
        v2_tasks_olap t ON
            (dt.task_id, dt.task_inserted_at) = (t.id, t.inserted_at)
    GROUP BY
        d.id, d.inserted_at
), updated_dags AS (
    UPDATE
        v2_dags_olap d
    SET
        readable_status = CASE
            -- If we only have queued events, we should keep the status as is
            WHEN dtc.queued_count = dtc.task_count THEN d.readable_status
            -- If we have any running or queued tasks, we should set the status to running
            WHEN dtc.running_count > 0 OR dtc.queued_count > 0 THEN 'RUNNING'
            WHEN dtc.failed_count > 0 THEN 'FAILED'
            WHEN dtc.cancelled_count > 0 THEN 'CANCELLED'
            WHEN dtc.completed_count = dtc.task_count THEN 'COMPLETED'
            ELSE 'RUNNING'
        END
    FROM
        dag_task_counts dtc
    WHERE
        (d.id, d.inserted_at) = (dtc.id, dtc.inserted_at)
), events_to_requeue AS (
    -- Get events which don't have a corresponding locked_task
    SELECT
        e.tenant_id,
        e.requeue_retries,
        e.dag_id,
        e.dag_inserted_at
    FROM
        locked_events e
    LEFT JOIN
        locked_dags d ON (e.tenant_id, e.dag_id, e.dag_inserted_at) = (d.tenant_id, d.id, d.inserted_at)
    WHERE
        d.id IS NULL
), deleted_events AS (
    DELETE FROM
        v2_task_status_updates_tmp
    WHERE
        (tenant_id, requeue_after, dag_id, id) IN (SELECT tenant_id, requeue_after, dag_id, id FROM locked_events)
), requeued_events AS (
    INSERT INTO
        v2_task_status_updates_tmp (
            tenant_id,
            requeue_after,
            requeue_retries,
            dag_id,
            dag_inserted_at
        )
    SELECT
        tenant_id,
        -- Exponential backoff, we limit to 10 retries which is 2048 seconds/34 minutes
        CURRENT_TIMESTAMP + (2 ^ requeue_retries) * INTERVAL '2 seconds',
        requeue_retries + 1,
        dag_id,
        dag_inserted_at
    FROM
        events_to_requeue
    WHERE
        requeue_retries < 10
    RETURNING
        tenant_id, requeue_after, requeue_retries, id, dag_id, dag_inserted_at
)
SELECT
    COUNT(*)
FROM
    locked_events
`

type UpdateDAGStatusesParams struct {
	Partitionnumber int32       `json:"partitionnumber"`
	Tenantid        pgtype.UUID `json:"tenantid"`
	Eventlimit      int32       `json:"eventlimit"`
}

func (q *Queries) UpdateDAGStatuses(ctx context.Context, db DBTX, arg UpdateDAGStatusesParams) (int64, error) {
	row := db.QueryRow(ctx, updateDAGStatuses, arg.Partitionnumber, arg.Tenantid, arg.Eventlimit)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const updateTaskStatuses = `-- name: UpdateTaskStatuses :one
WITH locked_events AS (
    SELECT
        tenant_id, requeue_after, requeue_retries, id, task_id, task_inserted_at, event_type, readable_status, retry_count, worker_id
    FROM
        list_task_events_tmp(
            $1::int,
            $2::uuid,
            $3::int
        )
), max_retry_counts AS (
    SELECT
        tenant_id,
        task_id,
        task_inserted_at,
        MAX(retry_count) AS max_retry_count
    FROM
        locked_events
    GROUP BY
        tenant_id, task_id, task_inserted_at
), updatable_events AS (
    SELECT
        e.tenant_id,
        e.task_id,
        e.task_inserted_at,
        e.retry_count,
        e.worker_id,
        MAX(e.readable_status) AS max_readable_status
    FROM
        locked_events e
    JOIN
        max_retry_counts mrc ON
            e.tenant_id = mrc.tenant_id
            AND e.task_id = mrc.task_id
            AND e.task_inserted_at = mrc.task_inserted_at
            AND e.retry_count = mrc.max_retry_count
    GROUP BY
        e.tenant_id, e.task_id, e.task_inserted_at, e.retry_count, e.worker_id
), locked_tasks AS (
    SELECT
        t.tenant_id,
        t.id,
        t.inserted_at,
        e.retry_count,
        e.max_readable_status
    FROM
        v2_tasks_olap t
    JOIN
        updatable_events e ON
            (t.tenant_id, t.id, t.inserted_at) = (e.tenant_id, e.task_id, e.task_inserted_at)
    ORDER BY
        t.id
    FOR UPDATE
), updated_tasks AS (
    UPDATE
        v2_tasks_olap t
    SET
        readable_status = e.max_readable_status,
        latest_retry_count = e.retry_count,
        latest_worker_id = CASE WHEN e.worker_id IS NOT NULL THEN e.worker_id ELSE t.latest_worker_id END
    FROM
        updatable_events e
    WHERE
        (t.tenant_id, t.id, t.inserted_at) = (e.tenant_id, e.task_id, e.task_inserted_at)
        AND
            (
                -- if the retry count is greater than the latest retry count, update the status
                (
                    e.retry_count > t.latest_retry_count
                    AND e.max_readable_status != t.readable_status
                ) OR
                -- if the retry count is equal to the latest retry count, update the status if the status is greater
                (
                    e.retry_count = t.latest_retry_count
                    AND e.max_readable_status > t.readable_status
                )
            )
    RETURNING
        t.tenant_id, t.id, t.inserted_at
), events_to_requeue AS (
    -- Get events which don't have a corresponding locked_task
    SELECT
        e.tenant_id,
        e.requeue_retries,
        e.task_id,
        e.task_inserted_at,
        e.event_type,
        e.readable_status,
        e.retry_count
    FROM
        locked_events e
    LEFT JOIN
        locked_tasks t ON (e.tenant_id, e.task_id, e.task_inserted_at) = (t.tenant_id, t.id, t.inserted_at)
    WHERE
        t.id IS NULL
), deleted_events AS (
    DELETE FROM
        v2_task_events_olap_tmp
    WHERE
        (tenant_id, requeue_after, task_id, id) IN (SELECT tenant_id, requeue_after, task_id, id FROM locked_events)
), requeued_events AS (
    INSERT INTO
        v2_task_events_olap_tmp (
            tenant_id,
            requeue_after,
            requeue_retries,
            task_id,
            task_inserted_at,
            event_type,
            readable_status,
            retry_count
        )
    SELECT
        tenant_id,
        -- Exponential backoff, we limit to 10 retries which is 2048 seconds/34 minutes
        CURRENT_TIMESTAMP + (2 ^ requeue_retries) * INTERVAL '2 seconds',
        requeue_retries + 1,
        task_id,
        task_inserted_at,
        event_type,
        readable_status,
        retry_count
    FROM
        events_to_requeue
    WHERE
        requeue_retries < 10
    RETURNING
        tenant_id, requeue_after, requeue_retries, id, task_id, task_inserted_at, event_type, readable_status, retry_count, worker_id
)
SELECT
    COUNT(*)
FROM
    locked_events
`

type UpdateTaskStatusesParams struct {
	Partitionnumber int32       `json:"partitionnumber"`
	Tenantid        pgtype.UUID `json:"tenantid"`
	Eventlimit      int32       `json:"eventlimit"`
}

func (q *Queries) UpdateTaskStatuses(ctx context.Context, db DBTX, arg UpdateTaskStatusesParams) (int64, error) {
	row := db.QueryRow(ctx, updateTaskStatuses, arg.Partitionnumber, arg.Tenantid, arg.Eventlimit)
	var count int64
	err := row.Scan(&count)
	return count, err
}
