// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: durable_event_log.sql

package sqlcv1

import (
	"context"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

const createDurableEventLogCallbacks = `-- name: CreateDurableEventLogCallbacks :many
WITH inputs AS (
    SELECT
        UNNEST($1::BIGINT[]) AS durable_task_id,
        UNNEST($2::TIMESTAMPTZ[]) AS durable_task_inserted_at,
        UNNEST($3::TIMESTAMPTZ[]) AS inserted_at,
        UNNEST(CAST($4::TEXT[] AS v1_durable_event_log_callback_kind[])) AS kind,
        UNNEST($5::TEXT[]) AS key,
        UNNEST($6::BIGINT[]) AS node_id,
        UNNEST($7::BOOLEAN[]) AS is_satisfied,
        UNNEST($8::UUID[]) AS external_id
)
INSERT INTO v1_durable_event_log_callback (
    durable_task_id,
    durable_task_inserted_at,
    inserted_at,
    kind,
    key,
    node_id,
    is_satisfied,
    external_id
)
SELECT
    i.durable_task_id,
    i.durable_task_inserted_at,
    i.inserted_at,
    i.kind,
    i.key,
    i.node_id,
    i.is_satisfied,
    i.external_id
FROM
    inputs i
RETURNING tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, key, node_id, is_satisfied
`

type CreateDurableEventLogCallbacksParams struct {
	Durabletaskids         []int64              `json:"durabletaskids"`
	Durabletaskinsertedats []pgtype.Timestamptz `json:"durabletaskinsertedats"`
	Insertedats            []pgtype.Timestamptz `json:"insertedats"`
	Kinds                  []string             `json:"kinds"`
	Keys                   []string             `json:"keys"`
	Nodeids                []int64              `json:"nodeids"`
	Issatisfieds           []bool               `json:"issatisfieds"`
	Externalids            []uuid.UUID          `json:"externalids"`
}

func (q *Queries) CreateDurableEventLogCallbacks(ctx context.Context, db DBTX, arg CreateDurableEventLogCallbacksParams) ([]*V1DurableEventLogCallback, error) {
	rows, err := db.Query(ctx, createDurableEventLogCallbacks,
		arg.Durabletaskids,
		arg.Durabletaskinsertedats,
		arg.Insertedats,
		arg.Kinds,
		arg.Keys,
		arg.Nodeids,
		arg.Issatisfieds,
		arg.Externalids,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*V1DurableEventLogCallback
	for rows.Next() {
		var i V1DurableEventLogCallback
		if err := rows.Scan(
			&i.TenantID,
			&i.ExternalID,
			&i.InsertedAt,
			&i.ID,
			&i.DurableTaskID,
			&i.DurableTaskInsertedAt,
			&i.Kind,
			&i.Key,
			&i.NodeID,
			&i.IsSatisfied,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const createDurableEventLogEntries = `-- name: CreateDurableEventLogEntries :many

WITH inputs AS (
    SELECT
        UNNEST($1::UUID[]) AS external_id,
        UNNEST($2::BIGINT[]) AS durable_task_id,
        UNNEST($3::TIMESTAMPTZ[]) AS durable_task_inserted_at,
        UNNEST($4::TIMESTAMPTZ[]) AS inserted_at,
        UNNEST(CAST($5::TEXT[] AS v1_durable_event_log_entry_kind[])) AS kind,
        UNNEST($6::BIGINT[]) AS node_id,
        UNNEST($7::BIGINT[]) AS parent_node_id,
        UNNEST($8::BIGINT[]) AS branch_id,
        UNNEST($9::BYTEA[]) AS data_hash,
        UNNEST($10::TEXT[]) AS data_hash_alg,
        -- todo: probably need an override here since this can be null
        UNNEST($11::UUID[]) AS triggered_run_external_id
), latest_node_ids AS (
    SELECT
        durable_task_id,
        durable_task_inserted_at,
        MAX(node_id) AS latest_node_id
    FROM inputs
    GROUP BY durable_task_id, durable_task_inserted_at
), inserts AS (
    INSERT INTO v1_durable_event_log_entry (
        external_id,
        durable_task_id,
        durable_task_inserted_at,
        inserted_at,
        kind,
        node_id,
        parent_node_id,
        branch_id,
        data_hash,
        data_hash_alg,
        triggered_run_external_id
    )
    SELECT
        i.external_id,
        i.durable_task_id,
        i.durable_task_inserted_at,
        i.inserted_at,
        i.kind,
        i.node_id,
        -- todo: check on if 0 is a safe sentinel value here or if we're zero-indexing the node id
        NULLIF(i.parent_node_id, 0),
        i.branch_id,
        i.data_hash,
        i.data_hash_alg,
        i.triggered_run_external_id
    FROM
        inputs i
    ORDER BY
        i.durable_task_id,
        i.durable_task_inserted_at,
        i.node_id
    -- todo: conflict resolution here
    RETURNING tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, node_id, parent_node_id, branch_id, data_hash, data_hash_alg, triggered_run_external_id
), node_id_update AS (
    -- todo: might need to explicitly lock here before the initial select / inserts
    UPDATE v1_durable_event_log_file AS f
    SET latest_node_id = GREATEST(f.latest_node_id, l.latest_node_id)
    FROM latest_node_ids l
    WHERE
        f.durable_task_id = l.durable_task_id
        AND f.durable_task_inserted_at = l.durable_task_inserted_at
)

SELECT tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, node_id, parent_node_id, branch_id, data_hash, data_hash_alg, triggered_run_external_id
FROM inserts
`

type CreateDurableEventLogEntriesParams struct {
	Externalids            []uuid.UUID          `json:"externalids"`
	Durabletaskids         []int64              `json:"durabletaskids"`
	Durabletaskinsertedats []pgtype.Timestamptz `json:"durabletaskinsertedats"`
	Insertedats            []pgtype.Timestamptz `json:"insertedats"`
	Kinds                  []string             `json:"kinds"`
	Nodeids                []int64              `json:"nodeids"`
	Parentnodeids          []int64              `json:"parentnodeids"`
	Branchids              []int64              `json:"branchids"`
	Datahashes             [][]byte             `json:"datahashes"`
	Datahashalgs           []string             `json:"datahashalgs"`
	Childrunexternalids    []uuid.UUID          `json:"childrunexternalids"`
}

type CreateDurableEventLogEntriesRow struct {
	TenantID               uuid.UUID                      `json:"tenant_id"`
	ExternalID             uuid.UUID                      `json:"external_id"`
	InsertedAt             pgtype.Timestamptz             `json:"inserted_at"`
	ID                     int64                          `json:"id"`
	DurableTaskID          int64                          `json:"durable_task_id"`
	DurableTaskInsertedAt  pgtype.Timestamptz             `json:"durable_task_inserted_at"`
	Kind                   NullV1DurableEventLogEntryKind `json:"kind"`
	NodeID                 int64                          `json:"node_id"`
	ParentNodeID           pgtype.Int8                    `json:"parent_node_id"`
	BranchID               int64                          `json:"branch_id"`
	DataHash               []byte                         `json:"data_hash"`
	DataHashAlg            pgtype.Text                    `json:"data_hash_alg"`
	TriggeredRunExternalID *uuid.UUID                     `json:"triggered_run_external_id"`
}

// todo: implement UpdateLatestNodeId
func (q *Queries) CreateDurableEventLogEntries(ctx context.Context, db DBTX, arg CreateDurableEventLogEntriesParams) ([]*CreateDurableEventLogEntriesRow, error) {
	rows, err := db.Query(ctx, createDurableEventLogEntries,
		arg.Externalids,
		arg.Durabletaskids,
		arg.Durabletaskinsertedats,
		arg.Insertedats,
		arg.Kinds,
		arg.Nodeids,
		arg.Parentnodeids,
		arg.Branchids,
		arg.Datahashes,
		arg.Datahashalgs,
		arg.Childrunexternalids,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*CreateDurableEventLogEntriesRow
	for rows.Next() {
		var i CreateDurableEventLogEntriesRow
		if err := rows.Scan(
			&i.TenantID,
			&i.ExternalID,
			&i.InsertedAt,
			&i.ID,
			&i.DurableTaskID,
			&i.DurableTaskInsertedAt,
			&i.Kind,
			&i.NodeID,
			&i.ParentNodeID,
			&i.BranchID,
			&i.DataHash,
			&i.DataHashAlg,
			&i.TriggeredRunExternalID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const createDurableEventLogFile = `-- name: CreateDurableEventLogFile :many
WITH inputs AS (
    SELECT
        UNNEST($1::BIGINT[]) AS durable_task_id,
        UNNEST($2::TIMESTAMPTZ[]) AS durable_task_inserted_at,
        UNNEST($3::TIMESTAMPTZ[]) AS latest_inserted_at,
        UNNEST($4::BIGINT[]) AS latest_node_id,
        UNNEST($5::BIGINT[]) AS latest_branch_id,
        UNNEST($6::BIGINT[]) AS latest_branch_first_parent_node_id
)
INSERT INTO v1_durable_event_log_file (
    durable_task_id,
    durable_task_inserted_at,
    latest_inserted_at,
    latest_node_id,
    latest_branch_id,
    latest_branch_first_parent_node_id
)
SELECT
    i.durable_task_id,
    i.durable_task_inserted_at,
    i.latest_inserted_at,
    i.latest_node_id,
    i.latest_branch_id,
    i.latest_branch_first_parent_node_id
FROM
    inputs i
RETURNING tenant_id, durable_task_id, durable_task_inserted_at, latest_inserted_at, latest_node_id, latest_branch_id, latest_branch_first_parent_node_id
`

type CreateDurableEventLogFileParams struct {
	Durabletaskids                 []int64              `json:"durabletaskids"`
	Durabletaskinsertedats         []pgtype.Timestamptz `json:"durabletaskinsertedats"`
	Latestinsertedats              []pgtype.Timestamptz `json:"latestinsertedats"`
	Latestnodeids                  []int64              `json:"latestnodeids"`
	Latestbranchids                []int64              `json:"latestbranchids"`
	Latestbranchfirstparentnodeids []int64              `json:"latestbranchfirstparentnodeids"`
}

func (q *Queries) CreateDurableEventLogFile(ctx context.Context, db DBTX, arg CreateDurableEventLogFileParams) ([]*V1DurableEventLogFile, error) {
	rows, err := db.Query(ctx, createDurableEventLogFile,
		arg.Durabletaskids,
		arg.Durabletaskinsertedats,
		arg.Latestinsertedats,
		arg.Latestnodeids,
		arg.Latestbranchids,
		arg.Latestbranchfirstparentnodeids,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*V1DurableEventLogFile
	for rows.Next() {
		var i V1DurableEventLogFile
		if err := rows.Scan(
			&i.TenantID,
			&i.DurableTaskID,
			&i.DurableTaskInsertedAt,
			&i.LatestInsertedAt,
			&i.LatestNodeID,
			&i.LatestBranchID,
			&i.LatestBranchFirstParentNodeID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDurableEventLogCallback = `-- name: GetDurableEventLogCallback :one
SELECT tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, key, node_id, is_satisfied
FROM v1_durable_event_log_callback
WHERE durable_task_id = $1
  AND durable_task_inserted_at = $2
  AND key = $3
`

type GetDurableEventLogCallbackParams struct {
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
	Key                   string             `json:"key"`
}

func (q *Queries) GetDurableEventLogCallback(ctx context.Context, db DBTX, arg GetDurableEventLogCallbackParams) (*V1DurableEventLogCallback, error) {
	row := db.QueryRow(ctx, getDurableEventLogCallback, arg.Durabletaskid, arg.Durabletaskinsertedat, arg.Key)
	var i V1DurableEventLogCallback
	err := row.Scan(
		&i.TenantID,
		&i.ExternalID,
		&i.InsertedAt,
		&i.ID,
		&i.DurableTaskID,
		&i.DurableTaskInsertedAt,
		&i.Kind,
		&i.Key,
		&i.NodeID,
		&i.IsSatisfied,
	)
	return &i, err
}

const getDurableEventLogEntry = `-- name: GetDurableEventLogEntry :one
SELECT tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, node_id, parent_node_id, branch_id, data_hash, data_hash_alg, triggered_run_external_id
FROM v1_durable_event_log_entry
WHERE durable_task_id = $1
  AND durable_task_inserted_at = $2
  AND node_id = $3
`

type GetDurableEventLogEntryParams struct {
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
	Nodeid                int64              `json:"nodeid"`
}

func (q *Queries) GetDurableEventLogEntry(ctx context.Context, db DBTX, arg GetDurableEventLogEntryParams) (*V1DurableEventLogEntry, error) {
	row := db.QueryRow(ctx, getDurableEventLogEntry, arg.Durabletaskid, arg.Durabletaskinsertedat, arg.Nodeid)
	var i V1DurableEventLogEntry
	err := row.Scan(
		&i.TenantID,
		&i.ExternalID,
		&i.InsertedAt,
		&i.ID,
		&i.DurableTaskID,
		&i.DurableTaskInsertedAt,
		&i.Kind,
		&i.NodeID,
		&i.ParentNodeID,
		&i.BranchID,
		&i.DataHash,
		&i.DataHashAlg,
		&i.TriggeredRunExternalID,
	)
	return &i, err
}

const getOrCreateEventLogFileForTask = `-- name: GetOrCreateEventLogFileForTask :one
INSERT INTO v1_durable_event_log_file (
    durable_task_id,
    durable_task_inserted_at,
    latest_inserted_at,
    latest_node_id,
    latest_branch_id,
    latest_branch_first_parent_node_id
)
VALUES (
    $1::BIGINT,
    $2::TIMESTAMPTZ,
    $3::TIMESTAMPTZ,
    $4::BIGINT,
    $5::BIGINT,
    $6::BIGINT
)
ON CONFLICT (durable_task_id, durable_task_inserted_at) DO NOTHING
RETURNING tenant_id, durable_task_id, durable_task_inserted_at, latest_inserted_at, latest_node_id, latest_branch_id, latest_branch_first_parent_node_id
`

type GetOrCreateEventLogFileForTaskParams struct {
	Durabletaskid                 int64              `json:"durabletaskid"`
	Durabletaskinsertedat         pgtype.Timestamptz `json:"durabletaskinsertedat"`
	Latestinsertedat              pgtype.Timestamptz `json:"latestinsertedat"`
	Latestnodeid                  int64              `json:"latestnodeid"`
	Latestbranchid                int64              `json:"latestbranchid"`
	Latestbranchfirstparentnodeid int64              `json:"latestbranchfirstparentnodeid"`
}

func (q *Queries) GetOrCreateEventLogFileForTask(ctx context.Context, db DBTX, arg GetOrCreateEventLogFileForTaskParams) (*V1DurableEventLogFile, error) {
	row := db.QueryRow(ctx, getOrCreateEventLogFileForTask,
		arg.Durabletaskid,
		arg.Durabletaskinsertedat,
		arg.Latestinsertedat,
		arg.Latestnodeid,
		arg.Latestbranchid,
		arg.Latestbranchfirstparentnodeid,
	)
	var i V1DurableEventLogFile
	err := row.Scan(
		&i.TenantID,
		&i.DurableTaskID,
		&i.DurableTaskInsertedAt,
		&i.LatestInsertedAt,
		&i.LatestNodeID,
		&i.LatestBranchID,
		&i.LatestBranchFirstParentNodeID,
	)
	return &i, err
}

const listDurableEventLogCallbacks = `-- name: ListDurableEventLogCallbacks :many
SELECT tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, key, node_id, is_satisfied
FROM v1_durable_event_log_callback
WHERE durable_task_id = $1
  AND durable_task_inserted_at = $2
ORDER BY inserted_at ASC
`

type ListDurableEventLogCallbacksParams struct {
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
}

func (q *Queries) ListDurableEventLogCallbacks(ctx context.Context, db DBTX, arg ListDurableEventLogCallbacksParams) ([]*V1DurableEventLogCallback, error) {
	rows, err := db.Query(ctx, listDurableEventLogCallbacks, arg.Durabletaskid, arg.Durabletaskinsertedat)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*V1DurableEventLogCallback
	for rows.Next() {
		var i V1DurableEventLogCallback
		if err := rows.Scan(
			&i.TenantID,
			&i.ExternalID,
			&i.InsertedAt,
			&i.ID,
			&i.DurableTaskID,
			&i.DurableTaskInsertedAt,
			&i.Kind,
			&i.Key,
			&i.NodeID,
			&i.IsSatisfied,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDurableEventLogEntries = `-- name: ListDurableEventLogEntries :many
SELECT tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, node_id, parent_node_id, branch_id, data_hash, data_hash_alg, triggered_run_external_id
FROM v1_durable_event_log_entry
WHERE durable_task_id = $1
  AND durable_task_inserted_at = $2
ORDER BY node_id ASC
`

type ListDurableEventLogEntriesParams struct {
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
}

func (q *Queries) ListDurableEventLogEntries(ctx context.Context, db DBTX, arg ListDurableEventLogEntriesParams) ([]*V1DurableEventLogEntry, error) {
	rows, err := db.Query(ctx, listDurableEventLogEntries, arg.Durabletaskid, arg.Durabletaskinsertedat)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*V1DurableEventLogEntry
	for rows.Next() {
		var i V1DurableEventLogEntry
		if err := rows.Scan(
			&i.TenantID,
			&i.ExternalID,
			&i.InsertedAt,
			&i.ID,
			&i.DurableTaskID,
			&i.DurableTaskInsertedAt,
			&i.Kind,
			&i.NodeID,
			&i.ParentNodeID,
			&i.BranchID,
			&i.DataHash,
			&i.DataHashAlg,
			&i.TriggeredRunExternalID,
		); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const updateDurableEventLogCallbackSatisfied = `-- name: UpdateDurableEventLogCallbackSatisfied :one
UPDATE v1_durable_event_log_callback
SET is_satisfied = $1
WHERE durable_task_id = $2
  AND durable_task_inserted_at = $3
  AND key = $4
RETURNING tenant_id, external_id, inserted_at, id, durable_task_id, durable_task_inserted_at, kind, key, node_id, is_satisfied
`

type UpdateDurableEventLogCallbackSatisfiedParams struct {
	Issatisfied           bool               `json:"issatisfied"`
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
	Key                   string             `json:"key"`
}

func (q *Queries) UpdateDurableEventLogCallbackSatisfied(ctx context.Context, db DBTX, arg UpdateDurableEventLogCallbackSatisfiedParams) (*V1DurableEventLogCallback, error) {
	row := db.QueryRow(ctx, updateDurableEventLogCallbackSatisfied,
		arg.Issatisfied,
		arg.Durabletaskid,
		arg.Durabletaskinsertedat,
		arg.Key,
	)
	var i V1DurableEventLogCallback
	err := row.Scan(
		&i.TenantID,
		&i.ExternalID,
		&i.InsertedAt,
		&i.ID,
		&i.DurableTaskID,
		&i.DurableTaskInsertedAt,
		&i.Kind,
		&i.Key,
		&i.NodeID,
		&i.IsSatisfied,
	)
	return &i, err
}

const updateLatestNodeId = `-- name: UpdateLatestNodeId :one
UPDATE v1_durable_event_log_file
SET latest_node_id = $1::BIGINT
WHERE
    durable_task_id = $2
    AND durable_task_inserted_at = $3
RETURNING tenant_id, durable_task_id, durable_task_inserted_at, latest_inserted_at, latest_node_id, latest_branch_id, latest_branch_first_parent_node_id
`

type UpdateLatestNodeIdParams struct {
	Latestnodeid          int64              `json:"latestnodeid"`
	Durabletaskid         int64              `json:"durabletaskid"`
	Durabletaskinsertedat pgtype.Timestamptz `json:"durabletaskinsertedat"`
}

func (q *Queries) UpdateLatestNodeId(ctx context.Context, db DBTX, arg UpdateLatestNodeIdParams) (*V1DurableEventLogFile, error) {
	row := db.QueryRow(ctx, updateLatestNodeId, arg.Latestnodeid, arg.Durabletaskid, arg.Durabletaskinsertedat)
	var i V1DurableEventLogFile
	err := row.Scan(
		&i.TenantID,
		&i.DurableTaskID,
		&i.DurableTaskInsertedAt,
		&i.LatestInsertedAt,
		&i.LatestNodeID,
		&i.LatestBranchID,
		&i.LatestBranchFirstParentNodeID,
	)
	return &i, err
}
