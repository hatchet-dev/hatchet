import { Snippet } from '@/next/lib/docs/generated/snips/types';

const snippet: Snippet = {
  language: 'python',
  content:
    "import asyncio\nimport json\nfrom contextlib import asynccontextmanager\nfrom typing import AsyncGenerator, cast\nfrom uuid import uuid4\n\nimport pytest\nfrom pydantic import BaseModel\n\nfrom examples.events.worker import EventWorkflowInput, event_workflow\nfrom hatchet_sdk.clients.events import (\n    BulkPushEventOptions,\n    BulkPushEventWithMetadata,\n    PushEventOptions,\n)\nfrom hatchet_sdk.clients.rest.models.v1_task_status import V1TaskStatus\nfrom hatchet_sdk.clients.rest.models.v1_task_summary import V1TaskSummary\nfrom hatchet_sdk.contracts.events_pb2 import Event\nfrom hatchet_sdk.hatchet import Hatchet\n\n\nclass ProcessedEvent(BaseModel):\n    id: str\n    payload: dict[str, str | bool]\n    meta: dict[str, str | bool | int]\n    should_have_runs: bool\n    test_run_id: str\n\n    def __hash__(self) -> int:\n        return hash(self.model_dump_json())\n\n\n@asynccontextmanager\nasync def event_filter(\n    hatchet: Hatchet,\n    test_run_id: str,\n    expression: str | None = None,\n    payload: dict[str, str] = {},\n) -> AsyncGenerator[None, None]:\n    expression = (\n        expression\n        or f'input.should_skip == false && payload.testRunId == '{test_run_id}''\n    )\n\n    f = await hatchet.filters.aio_create(\n        workflow_id=event_workflow.id,\n        expression=expression,\n        scope=test_run_id,\n        payload={'testRunId': test_run_id, **payload},\n    )\n\n    yield\n\n    await hatchet.filters.aio_delete(f.metadata.id)\n\n\nasync def fetch_runs_for_event(\n    hatchet: Hatchet, event: Event\n) -> tuple[ProcessedEvent, list[V1TaskSummary]]:\n    runs = await hatchet.runs.aio_list(triggering_event_external_id=event.eventId)\n\n    meta = (\n        cast(dict[str, str | int | bool], json.loads(event.additionalMetadata))\n        if event.additionalMetadata\n        else {}\n    )\n    payload = (\n        cast(dict[str, str | bool], json.loads(event.payload)) if event.payload else {}\n    )\n\n    return (\n        ProcessedEvent(\n            id=event.eventId,\n            payload=payload,\n            meta=meta,\n            should_have_runs=meta.get('should_have_runs', False) is True,\n            test_run_id=cast(str, meta['test_run_id']),\n        ),\n        runs.rows or [],\n    )\n\n\nasync def wait_for_result(\n    hatchet: Hatchet, events: list[Event]\n) -> dict[ProcessedEvent, list[V1TaskSummary]]:\n    await asyncio.sleep(3)\n\n    persisted = (await hatchet.event.aio_list(limit=100)).rows or []\n\n    assert {e.eventId for e in events}.issubset({e.metadata.id for e in persisted})\n\n    iters = 0\n    while True:\n        print('Waiting for event runs to complete...')\n        if iters > 15:\n            print('Timed out waiting for event runs to complete.')\n            return {}\n\n        iters += 1\n\n        event_runs = await asyncio.gather(\n            *[fetch_runs_for_event(hatchet, event) for event in events]\n        )\n\n        all_empty = all(not event_run for _, event_run in event_runs)\n\n        if all_empty:\n            await asyncio.sleep(1)\n            continue\n\n        event_id_to_runs = {event_id: runs for (event_id, runs) in event_runs}\n\n        any_queued_or_running = any(\n            run.status in [V1TaskStatus.QUEUED, V1TaskStatus.RUNNING]\n            for runs in event_id_to_runs.values()\n            for run in runs\n        )\n\n        if any_queued_or_running:\n            await asyncio.sleep(1)\n            continue\n\n        break\n\n    return event_id_to_runs\n\n\nasync def assert_event_runs_processed(\n    event: ProcessedEvent,\n    runs: list[V1TaskSummary],\n) -> None:\n    if event.should_have_runs:\n        assert len(runs) > 0\n    else:\n        assert len(runs) == 0\n\n\ndef bpi(\n    index: int = 1,\n    test_run_id: str = '',\n    should_skip: bool = False,\n    should_have_runs: bool = True,\n    key: str = 'user:create',\n    payload: dict[str, str] = {},\n    scope: str | None = None,\n) -> BulkPushEventWithMetadata:\n    return BulkPushEventWithMetadata(\n        key=key,\n        payload={\n            'should_skip': should_skip,\n            **payload,\n        },\n        additional_metadata={\n            'should_have_runs': should_have_runs,\n            'test_run_id': test_run_id,\n            'key': index,\n        },\n        scope=scope,\n    )\n\n\ndef cp(should_skip: bool) -> dict[str, bool]:\n    return EventWorkflowInput(should_skip=should_skip).model_dump()\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_push(hatchet: Hatchet) -> None:\n    e = hatchet.event.push('user:create', cp(False))\n\n    assert e.eventId is not None\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_async_event_push(hatchet: Hatchet) -> None:\n    e = await hatchet.event.aio_push('user:create', cp(False))\n\n    assert e.eventId is not None\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_async_event_bulk_push(hatchet: Hatchet) -> None:\n    events = [\n        BulkPushEventWithMetadata(\n            key='event1',\n            payload={'message': 'This is event 1', 'should_skip': False},\n            additional_metadata={'source': 'test', 'user_id': 'user123'},\n        ),\n        BulkPushEventWithMetadata(\n            key='event2',\n            payload={'message': 'This is event 2', 'should_skip': False},\n            additional_metadata={'source': 'test', 'user_id': 'user456'},\n        ),\n        BulkPushEventWithMetadata(\n            key='event3',\n            payload={'message': 'This is event 3', 'should_skip': False},\n            additional_metadata={'source': 'test', 'user_id': 'user789'},\n        ),\n    ]\n    opts = BulkPushEventOptions(namespace='bulk-test')\n\n    e = await hatchet.event.aio_bulk_push(events, opts)\n\n    assert len(e) == 3\n\n    # Sort both lists of events by their key to ensure comparison order\n    sorted_events = sorted(events, key=lambda x: x.key)\n    sorted_returned_events = sorted(e, key=lambda x: x.key)\n    namespace = 'bulk-test'\n\n    # Check that the returned events match the original events\n    for original_event, returned_event in zip(sorted_events, sorted_returned_events):\n        assert returned_event.key == namespace + original_event.key\n\n\n@pytest.fixture(scope='function')\ndef test_run_id() -> str:\n    return str(uuid4())\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_engine_behavior(hatchet: Hatchet) -> None:\n    test_run_id = str(uuid4())\n    events = [\n        bpi(\n            test_run_id=test_run_id,\n        ),\n        bpi(\n            test_run_id=test_run_id,\n            key='thisisafakeeventfoobarbaz',\n            should_have_runs=False,\n        ),\n    ]\n\n    print('Events:', events)\n\n    result = await hatchet.event.aio_bulk_push(events)\n\n    print('Result:', result)\n\n    runs = await wait_for_result(hatchet, result)\n\n    for event, r in runs.items():\n        await assert_event_runs_processed(event, r)\n\n\ndef gen_bulk_events(test_run_id: str) -> list[BulkPushEventWithMetadata]:\n    return [\n        bpi(\n            index=1,\n            test_run_id=test_run_id,\n            should_skip=False,\n            should_have_runs=True,\n        ),\n        bpi(\n            index=2,\n            test_run_id=test_run_id,\n            should_skip=True,\n            should_have_runs=True,\n        ),\n        bpi(\n            index=3,\n            test_run_id=test_run_id,\n            should_skip=False,\n            should_have_runs=True,\n            scope=test_run_id,\n        ),\n        bpi(\n            index=4,\n            test_run_id=test_run_id,\n            should_skip=True,\n            should_have_runs=False,\n            scope=test_run_id,\n        ),\n        bpi(\n            index=5,\n            test_run_id=test_run_id,\n            should_skip=True,\n            should_have_runs=False,\n            scope=test_run_id,\n            key='thisisafakeeventfoobarbaz',\n        ),\n        bpi(\n            index=6,\n            test_run_id=test_run_id,\n            should_skip=False,\n            should_have_runs=False,\n            scope=test_run_id,\n            key='thisisafakeeventfoobarbaz',\n        ),\n    ]\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_skipping_filtering(hatchet: Hatchet, test_run_id: str) -> None:\n    async with event_filter(hatchet, test_run_id):\n        events = gen_bulk_events(test_run_id)\n\n        result = await hatchet.event.aio_bulk_push(events)\n\n        runs = await wait_for_result(hatchet, result)\n        for e, r in runs.items():\n            await assert_event_runs_processed(e, r)\n\n\nasync def bulk_to_single(hatchet: Hatchet, event: BulkPushEventWithMetadata) -> Event:\n    return await hatchet.event.aio_push(\n        event_key=event.key,\n        payload=event.payload,\n        options=PushEventOptions(\n            scope=event.scope,\n            additional_metadata=event.additional_metadata,\n            priority=event.priority,\n        ),\n    )\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_skipping_filtering_no_bulk(\n    hatchet: Hatchet, test_run_id: str\n) -> None:\n    async with event_filter(hatchet, test_run_id):\n        raw_events = gen_bulk_events(test_run_id)\n        events = await asyncio.gather(\n            *[bulk_to_single(hatchet, event) for event in raw_events]\n        )\n\n        result = await wait_for_result(hatchet, events)\n        for event, runs in result.items():\n            await assert_event_runs_processed(event, runs)\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_payload_filtering(hatchet: Hatchet, test_run_id: str) -> None:\n    async with event_filter(\n        hatchet,\n        test_run_id,\n        'input.should_skip == false && payload.foobar == 'baz'',\n        {'foobar': 'qux'},\n    ):\n        event = await hatchet.event.aio_push(\n            event_key='user:create',\n            payload={'message': 'This is event 1', 'should_skip': False},\n            options=PushEventOptions(\n                scope=test_run_id,\n                additional_metadata={\n                    'should_have_runs': False,\n                    'test_run_id': test_run_id,\n                    'key': 1,\n                },\n            ),\n        )\n\n        runs = await wait_for_result(hatchet, [event])\n        assert len(runs) == 0\n\n\n@pytest.mark.asyncio(loop_scope='session')\nasync def test_event_payload_filtering_with_payload_match(\n    hatchet: Hatchet, test_run_id: str\n) -> None:\n    async with event_filter(\n        hatchet,\n        test_run_id,\n        'input.should_skip == false && payload.foobar == 'baz'',\n        {'foobar': 'baz'},\n    ):\n        event = await hatchet.event.aio_push(\n            event_key='user:create',\n            payload={'message': 'This is event 1', 'should_skip': False},\n            options=PushEventOptions(\n                scope=test_run_id,\n                additional_metadata={\n                    'should_have_runs': True,\n                    'test_run_id': test_run_id,\n                    'key': 1,\n                },\n            ),\n        )\n        runs = await wait_for_result(hatchet, [event])\n        assert len(runs) == 1\n",
  source: 'out/python/events/test_event.py',
  blocks: {},
  highlights: {},
}; // Then replace double quotes with single quotes

export default snippet;
