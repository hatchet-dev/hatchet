import { Snippet } from '@/next/lib/docs/generated/snips/types';

const snippet: Snippet = {
  language: 'python',
  content:
    'import asyncio\nfrom datetime import datetime, timedelta, timezone\nfrom uuid import uuid4\n\nimport pytest\n\nfrom examples.bulk_operations.worker import (\n    bulk_replay_test_1,\n    bulk_replay_test_2,\n    bulk_replay_test_3,\n)\nfrom hatchet_sdk import BulkCancelReplayOpts, Hatchet, RunFilter, TriggerWorkflowOptions\nfrom hatchet_sdk.clients.rest.models.v1_task_status import V1TaskStatus\n\n\n@pytest.mark.asyncio(loop_scope="session")\nasync def test_bulk_replay(hatchet: Hatchet) -> None:\n    test_run_id = str(uuid4())\n    n = 100\n\n    with pytest.raises(Exception):\n        await bulk_replay_test_1.aio_run_many(\n            [\n                bulk_replay_test_1.create_bulk_run_item(\n                    options=TriggerWorkflowOptions(\n                        additional_metadata={\n                            "test_run_id": test_run_id,\n                        }\n                    )\n                )\n                for _ in range(n + 1)\n            ]\n        )\n\n    with pytest.raises(Exception):\n        await bulk_replay_test_2.aio_run_many(\n            [\n                bulk_replay_test_2.create_bulk_run_item(\n                    options=TriggerWorkflowOptions(\n                        additional_metadata={\n                            "test_run_id": test_run_id,\n                        }\n                    )\n                )\n                for _ in range((n // 2) - 1)\n            ]\n        )\n\n    with pytest.raises(Exception):\n        await bulk_replay_test_3.aio_run_many(\n            [\n                bulk_replay_test_3.create_bulk_run_item(\n                    options=TriggerWorkflowOptions(\n                        additional_metadata={\n                            "test_run_id": test_run_id,\n                        }\n                    )\n                )\n                for _ in range((n // 2) - 2)\n            ]\n        )\n\n    workflow_ids = [\n        bulk_replay_test_1.id,\n        bulk_replay_test_2.id,\n        bulk_replay_test_3.id,\n    ]\n\n    ## Should result in two batches of replays\n    await hatchet.runs.aio_bulk_replay(\n        opts=BulkCancelReplayOpts(\n            filters=RunFilter(\n                workflow_ids=workflow_ids,\n                since=datetime.now(tz=timezone.utc) - timedelta(minutes=2),\n                additional_metadata={"test_run_id": test_run_id},\n            )\n        )\n    )\n\n    await asyncio.sleep(5)\n\n    runs = await hatchet.runs.aio_list(\n        workflow_ids=workflow_ids,\n        since=datetime.now(tz=timezone.utc) - timedelta(minutes=2),\n        additional_metadata={"test_run_id": test_run_id},\n        limit=1000,\n    )\n\n    assert len(runs.rows) == n + 1 + (n // 2 - 1) + (n // 2 - 2)\n\n    for run in runs.rows:\n        assert run.status == V1TaskStatus.COMPLETED\n        assert run.retry_count == 1\n        assert run.attempt == 2\n\n    assert (\n        len([r for r in runs.rows if r.workflow_id == bulk_replay_test_1.id]) == n + 1\n    )\n    assert (\n        len([r for r in runs.rows if r.workflow_id == bulk_replay_test_2.id])\n        == n // 2 - 1\n    )\n    assert (\n        len([r for r in runs.rows if r.workflow_id == bulk_replay_test_3.id])\n        == n // 2 - 2\n    )\n',
  source: 'out/python/bulk_operations/test_bulk_replay.py',
  blocks: {},
  highlights: {},
};

export default snippet;
