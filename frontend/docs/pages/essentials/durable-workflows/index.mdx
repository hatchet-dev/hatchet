---
asIndexPage: true
---
import { Cards } from "nextra/components";

# Durable Workflows

A **durable workflow** is work whose execution state lives in Hatchet instead of in your process. When you run a durable workflow, the **orchestrator** owns that state: it records progress, survives your worker crashing or scaling down, and resumes from the last checkpoint so work is not lost or duplicated.

## Execution state in the orchestrator

With ordinary tasks, "where we are" in the workflow lives in memory. If the process dies, that state is gone. With durable workflows, **execution state is stored durably** (e.g. in the Hatchet event log). Each logical step that changes state is recorded. The orchestrator can therefore:

- **Recover from failures**  - If a worker dies mid-run, Hatchet replays from the last recorded step and continues on another worker. You don't restart from scratch.
- **Handle long waits**  - Steps like "wait 24 hours" or "wait for this external event" are recorded. The worker can release the slot; when the wait completes, the orchestrator reschedules the workflow and it continues from that point.
- **Manage complex distributed state**  - Multi-step, branching, or long-running flows are expressed as a sequence of durable steps. The orchestrator keeps that state consistent and replayable across workers and restarts.

So the responsibility for **where we are** and **what has already happened** moves from your application to the Hatchet orchestrator. Your code describes the steps; Hatchet makes them durable and resumable.

## Two flavors of durable workflows

Hatchet offers two ways to build durable workflows:

The key difference is whether you know the **shape of work** ahead of time.

- **Durable task execution**  - The shape of work is **dynamic**. A single long-running function that checkpoints its progress (`SleepFor`, `WaitForEvent`, `Memo`) and can spawn child tasks at runtime. The number and type of children are determined as the task runs. Use durable tasks when the work is unpredictable: agentic path-finding, fan-outs where N is determined at runtime, human-in-the-loop approvals, or long waits.
- **DAGs (directed acyclic graphs)**  - The shape of work is **known upfront**. You declare which tasks run, in what order, and what depends on what. Use DAGs when you have a well-defined pipeline where the graph of tasks doesn't change between runs.

<Cards>
  <Cards.Card title="Durable Task Execution" href="/essentials/durable-workflows/durable-task-execution">
    How durable task execution works: checkpoints, context, and when to use it.
  </Cards.Card>
  <Cards.Card title="Directed Acyclic Graphs" href="/essentials/durable-workflows/directed-acyclic-graph">
    Define multi-task workflows with dependencies and parallel execution.
  </Cards.Card>
</Cards>

Want to dive deeper? The [Durable Workflows concepts page](/concepts/durable-workflows) covers workflow-level configuration, concurrency, on-failure tasks, and conditional workflows.
