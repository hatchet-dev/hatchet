import { Callout } from "nextra/components";

# Understanding Slots

Slots are the number of concurrent _task_ runs that a worker can execute. You configure them using the `slots` option on the worker. If you set `slots=5`, your worker will run up to five tasks at the same time. Any additional tasks will wait in the queue until a slot opens up.

You can increase throughput by raising the slot count on a single worker, by running more workers, or both. In many workloads the simplest path to higher throughput is adding workers, since each one brings its own pool of slots.

<Callout type="info">
  Slot-level concurrency is only helpful up to the point where the worker is not bottlenecked by another resource. If your worker is CPU-bound, memory-bound, or waiting on network I/O, adding more slots will not improve throughput—it will just increase contention. Profile your workload before increasing slots beyond a handful.
</Callout>

## Slots vs. concurrency controls

Slots are a **local** limit—they control how much work a single worker process takes on. [Concurrency controls](/concepts/concurrency) are a **global** limit—they control how many runs of a given task or workflow execute across your entire fleet at the same time.

The two work together. Concurrency controls decide how many runs Hatchet will allow to be active; slots decide how many of those runs each individual worker is willing to accept.

## Choosing a slot count

Start with a slot count that matches the degree of parallelism your worker can sustain. For CPU-heavy tasks, that is typically the number of available cores. For I/O-heavy tasks (HTTP calls, database queries), you can safely go higher because most of the time is spent waiting.

Monitor memory usage and event loop lag (if applicable) after changing slot counts. If either climbs, you have gone too far.

## Related

- [Worker Affinity](/concepts/worker-affinity) — route tasks to specific workers.
- [Manual Slot Release](/concepts/manual-slot-release) — free a slot before a task completes.
- [Concurrency](/concepts/concurrency) — global limits across all workers.
