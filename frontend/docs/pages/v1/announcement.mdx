import { Callout } from "nextra/components";

## ðŸª“ Hatchet `v1` is here!

For the past several months, weâ€™ve been working on a complete rewrite of the Hatchet queue with a focus on performance and a set of feature requests which werenâ€™t possible in the v0 architecture.

This discussion outlines the timeline, new features and breaking changes you can expect from the new release.

## Timeline

- **March 24th, 2025:** Hatchet v1 will be released on Hatchet Cloud and under the latest `v0.55.x` release bundled with the v0 Hatchet engine. It will be opt-in, meaning engine v0 will still be the default engine for each tenant.
- **March 24th-28th, 2025:** Hatchet v1 launch week! We will be highlighting a new feature or performance improvement in the v1 engine. You can get updates in our Discord [here](https://discord.gg/ZMeUafwH89) and we will be updating the top of our README [here](https://github.com/hatchet-dev/hatchet) with new announcements.
- **May 1st, 2025:** Hatchet v1 will become the new default engine for all Hatchet releases after this point. We will be releasing `v1.0.x` on this date.
- **September 30th, 2025:** Hatchet v0 enters EOL, and will no longer be bundled into the Hatchet runtime.

## New features

At a high level, Hatchet v1 supports the following new features:

- Complex/conditional workflow logic, like skipping or branching workflows
- Durable execution features: workflow signaling and durable sleep
- A documented, stable REST API for interacting with workflows
- Each SDK received a new `v1.0.x` release with the following improvements:
  - Python received improved support for Pydantic validation, dynamic workflow composition, simpler workflow and task declaration, and significantly improved type support.
  - Typescript received a new factory method for building workflows, and improved typing and validation support
  - Go received improvements for registering workflows and defining tasks.
- Improved bulk cancellations and replays

## Breaking changes

First, a quick note â€” we are **not removing any features from our existing feature set**. Our goal is for all features to work with minimal changes in Hatchet v1.

Up to now, weâ€™ve attempted to be as backwards-compatible as possible while keeping up with feature velocity, and weâ€™d like to support users on v0 for as long as possible while providing an easy path for upgrading. Generally, weâ€™d recommend upgrading the Hatchet engine first, followed by the SDK version. Hereâ€™s our compatibility matrix between v0 and v1:

|        | Engine v0           | Engine v1   |
| ------ | ------------------- | ----------- |
| SDK v0 | Supported           | Supported\* |
| SDK v1 | Limited support\*\* | Supported   |

<Callout type="info" emoji="ðŸª“">
  \* Some features will behave slightly differently on the v1 engine, but all
  workflows defined in v0 can be registered in v1
</Callout>

<Callout type="warning" emoji="ðŸš¨">
  \** It will not be possible to register a v1 workflow against the v0 engine,
  but each SDK will continue to bundle the v0 version until September 30th,
  2025.
</Callout>

### List of breaking changes

While weâ€™d prefer to avoid any breaking changes, v1 is architecturally very different from v0, which means that the following APIs will be modified/replaced:

- While we havenâ€™t published an official REST API doc, we have often recommended usage of the REST API in our SDKs to implement replays, retrieving task status, and dead-letter queueing. The current API for listing, cancelling and replaying workflow runs will not work against a v1 engine. We will be providing an upgrade path using new endpoints which are more conducive to bulk replays and cancellations.
- We will only be supporting [CEL-based concurrency keys](https://docs.hatchet.run/home/features/concurrency/round-robin#how-to-use-group_round_robin), and we will not be supporting custom concurrency methods defined on the client. If you require custom logic to compute the concurrency key that canâ€™t be captured in a CEL expression, we recommend computing the key ahead of time and passing it as part of the input to the workflow. **Workflows registered against a v1 engine with a custom concurrency method (instead of an expression) will not use a concurrency queue.**
- Concurrency queues previously did not respect the `ScheduleTimeout` value set on the workflow level, so concurrency queues had no timeouts. In v1, concurrency queues will respect the schedule timeout value as well.
- User-defined events sent via `event.push` are no longer displayed in the Hatchet UI and will not be available over the REST API. Events will still trigger workflows, but in nearly all instances of Hatchet that we surveyed, events were not used, accessed after writes, or replayed. We are considering adding an option to mark a user-defined event as `Durable`, but that will not be available in the initial v1 release. **Please let us know if you are dependent on the events view or APIs.**

_These are the most important breaking changes, but we will add any small modifications to queueing/workflow behavior ahead of March 24th._

## Terminology

We have gotten feedback that the terminology of Workflows and Steps is confusing, and weâ€™ve seen users use the terms steps/tasks/jobs/workflows interchangeably. In the next major release, we are calling each individual unit of work a **_Task_**, and we are calling the declaration of the work to do a **_Workflow_**. We believe that this naming translates more directly to what Hatchet is actually doing (we are a **_task queue_** built on Postgres, after all). When referring to an instance of a task or workflow, we will internally (and over our REST API) refer to these as **_Task Run_** or **_Workflow Run_**, respectively, though it should be clear from context whether a Workflow or a Task refers to the declaration of work or an instance of the work.

## Performance improvements

In our benchmarks so far, weâ€™ve seen:

- 30% lower latency, from 30ms â†’ 20ms average enqueue times
- 10x higher throughput, from about 1k events/s to 10k events/s
- Under significant load, we see about 6x less IOPs load and 5x less CPU load on the database

As part of the v1 rewrite, we will be releasing a new load testing container which is designed to benchmark Hatchet setups. We will be publishing a number of new benchmarks during our Launch Week.

## Migration guides

We have migration guides published to help you migrate existing code over to V1:

- v1 Self-Hosted Migration Guide (coming soon)
- [v1 Python SDK migration guide](./migration-guide-python.mdx)
- v1 Go SDK migration guide (coming soon)
- [v1 Typescript SDK migration guide](./migration-guide-typescript.mdx)

These links will become active when each migration guide is available.
