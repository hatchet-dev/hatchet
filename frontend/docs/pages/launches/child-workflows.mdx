# `v0.18` - Child Workflows

**TL;DR** - we're releasing `v0.18.0` of Hatchet, which adds support for child workflows. Child workflows allow you to spawn workflow runs on-the-fly, with support for durability by default. This means that even if your parent workflow fails, times out, or gets rescheduled, child workflows will only be spawned once, and the parent workflows will resume with all child workflows in an identical state. This is ideal for **dynamic error handling, scatter/gather, and fanout workflows**.

Here's a video that explains the feature in more detail:

<iframe
    className="aspect-video w-full my-4"
    src="https://www.youtube.com/embed/UKrfQsXqiPY?si=_dIQe9zOFUP34qQ6"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowFullScreen
/>

## What are child workflows?

While workflows in Hatchet implement a DAG, there are many cases where the structure of a workflow isn't known ahead of time. For example, you may have a batch processing workflow where the number of tasks is determined by the input - for example, running a workflow per page in a PDF. In these cases, you can use child workflows to dynamically create new workflows as needed.

![Child Workflow List](/child-workflows-1.png)

## Creating more durable workflows

We've had support for spawning new workflows programatically for a while, but there's a fundamental issue with this approach: if the parent workflow is retried or rescheduled, a new workflow will get spawned on each subsequent rerun. Ideally, we only spawn a child workflow once, and can simply replay the same state on the parent workflow if the parent gets retried. Parent workflows whose state are reliant only on the results of child workflows are **durably executed**.

For a practical example, say we have a workflow which extracts text from PDFs. PDF parsing and extraction is an expensive operation, so we'd like to parse each page separately, collect the text from each PDF, and pass it downstream to a future step in our workflow. We can model each page as a child workflow. For example, in the Typescript SDK:

```ts
async function (ctx) {
    const { pages } = ctx.workflowInput();
    const promises: Promise<Result>[] = [];

    for (let i = 0; i < pages; i++) {
        promises.push(ctx.spawnWorkflow<Result>('process-page', { page: i }).result());
    }

    const results = await Promise.all(promises);

    return {
        results,
    };
}
```

What happens if our workflow fails during the `await Promise.all`, for example when exceeding a timeout? Because we've already called `spawnWorkflow` for each page, when this workflow is rerun, we'll simply enter the `Promise.all` method again with the same child workflows.

By default, **child workflows are keyed on their index**. However, you can pass in custom keys if you expect that the index of your workflows would change between workflow runs.

## Advanced Use-Cases

Child workflows can be used to support more complex use-cases, like:

- [Error recovery](/features/child-workflows#error-handling)
- [Looping workflows](/features/child-workflows#looping-workflows)
- [Scatter/gather workflows](/features/child-workflows#scattergather-workflows)

## Feedback

Child workflows are available in engine version `v0.18.0` and above, and on all the latest SDK versions. We'd love to hear your feedback in our [Discord](https://discord.gg/ZMeUafwH89)!
