import { Callout, Cards, Steps } from "nextra/components";
import BatchProcessingDiagram from "@/components/BatchProcessingDiagramWrapper";

# Batch Processing

Batch processing involves running the same operation across a large set of items — images, documents, records, or API calls. This page covers how to structure batch workloads as Hatchet workflows with fan-out, retry, and concurrency control.

<BatchProcessingDiagram />

## Core Challenges

<Steps>

### Parallelism

A parent task fans out to one child per item. Hatchet distributes these across available workers. Adding more workers increases throughput without code changes.

### Partial failure

Each item is an independent task. If one fails, Hatchet retries just that item — the rest continue. You can also bulk-retry all failed items from the dashboard.

### Resource control

Concurrency limits prevent overwhelming your infrastructure. Rate limits protect external APIs. Priority queues let urgent batches run ahead of lower-priority work.

</Steps>

## Key Features

| Feature | What it does for batch processing |
|---------|----------------------------------|
| **[Child Spawning](/home/child-spawning)** | Fan out to one task per item with automatic distribution across workers |
| **[Bulk Run](/home/bulk-run)** | Trigger thousands of tasks in a single API call |
| **[Retry Policies](/home/retry-policies)** | Retry failed items individually without restarting the batch |
| **[Bulk Retries](/home/bulk-retries-and-cancellations)** | Re-run all failed items from the dashboard |
| **[Concurrency](/home/concurrency)** | Limit how many items process simultaneously |
| **[Rate Limits](/home/rate-limits)** | Throttle external API calls across all workers |
| **[Priority](/home/priority)** | Urgent batches jump ahead of lower-priority work |
| **[Autoscaling](/home/autoscaling-workers)** | Scale workers up during batch processing, down when idle |

<Callout type="info">
  The batch processing pattern is [Fanout](/home/patterns/fanout) applied at scale. For fixed multi-stage processing (e.g., validate → transform → load), combine with [Pre-Determined Pipelines](/home/patterns/pre-determined-pipelines).
</Callout>

## Architecture

<Steps>

### Trigger the batch

Start a parent workflow with the batch input — a list of item IDs, file paths, or records. This can come from an API call, event, cron schedule, or the dashboard.

### Fan out to workers

The parent task iterates over the input and spawns one child task per item. For very large batches (10,000+ items), use `BulkRunChild` for optimized dispatching.

### Process items

Each child task processes its item independently — calling external APIs, transforming data, writing results. Failed items are retried according to your retry policy.

### Collect results

The parent awaits all children and aggregates results. You can see the status of every item in real-time in the Hatchet dashboard.

</Steps>

<Callout type="warning">
  For batches with thousands of items, use **durable workflows** so the parent task doesn't hold a worker slot while waiting for all children to complete. See [Durable Workflows](/home/durable-workflows-overview) for details.
</Callout>

## Common Batch Patterns

| Pattern | Description |
|---------|------------|
| **Image processing** | Resize, transcode, or analyze images in parallel across workers |
| **Data enrichment** | Enrich records by calling external APIs (geocoding, company info, email validation) |
| **Report generation** | Generate per-customer reports in parallel, then aggregate into a summary |
| **Database migrations** | Process and migrate records in batches with retry and progress tracking |
| **Notification delivery** | Send emails, SMS, or push notifications to a user list with rate limiting |

## Related Patterns

<Cards>
  <Cards.Card title="Fanout" href="/home/patterns/fanout">
    The core pattern behind batch processing — spawn N children from a parent.
  </Cards.Card>
  <Cards.Card title="Pre-Determined Pipelines" href="/home/patterns/pre-determined-pipelines">
    Chain batch processing with multi-stage transforms in a DAG.
  </Cards.Card>
  <Cards.Card title="RAG & Indexing" href="/home/use-cases/rag-and-indexing">
    A specialized batch processing use case for document indexing pipelines.
  </Cards.Card>
  <Cards.Card title="Cycles" href="/home/patterns/cycles">
    Process paginated results one page at a time with iterative child spawning.
  </Cards.Card>
</Cards>

## Next Steps

- [Child Spawning](/home/child-spawning) — learn the fan-out API for batch processing
- [Bulk Run](/home/bulk-run) — trigger large batches efficiently
- [Concurrency Control](/home/concurrency) — limit concurrent item processing
- [Rate Limits](/home/rate-limits) — protect external APIs during batch operations
