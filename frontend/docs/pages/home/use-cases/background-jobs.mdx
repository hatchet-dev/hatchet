import { Callout, Cards, Steps } from "nextra/components";

# Background Job Migration

If you're outgrowing your current background task system — whether it's Celery, FastAPI BackgroundTasks, or Bull/BullMQ — this page covers what a migration to Hatchet looks like and what changes in practice.

## Common Problems with Background Job Systems

| Problem | Typical cause | How Hatchet handles it |
|---------|--------------|----------------------|
| **Lost tasks** | Worker crash or app restart drops in-flight work | Orphaned tasks are reassigned to healthy workers |
| **No visibility** | No built-in dashboard for task status | Dashboard shows every task's status, duration, and logs |
| **Inconsistent retries** | Retry logic varies per task, bolted on after the fact | Configurable retry policies with exponential backoff, applied per-task or per-workflow |
| **Resource contention** | Background tasks compete with the web server for CPU/memory | Workers run as separate processes, scaled independently |
| **Duplicate processing** | No built-in concurrency control or deduplication | Concurrency strategies and deduplication are built in |

<Callout type="info">
  Workers are processes that run your task handlers — deploy them alongside your web server or as separate services. See [Deploying Workers](/home/docker) for details.
</Callout>

## Migration Path

<Steps>

### Install the SDK

Add the Hatchet SDK to your project. Available for Python, TypeScript, and Go.

### Define tasks

Convert your existing background functions into Hatchet tasks. The function signature stays almost the same — you just wrap it with Hatchet's task decorator/builder.

### Configure triggers

Replace your framework-specific task dispatching (`background_tasks.add_task()`, `queue.add()`, `.delay()`) with Hatchet triggers. Tasks can be triggered via API, events, cron, or webhooks.

### Deploy workers

Run your Hatchet workers alongside (or instead of) your existing worker processes. Workers connect to Hatchet and pull tasks automatically.

### Observe and iterate

Use the Hatchet dashboard to monitor task execution, identify failures, and bulk-retry failed tasks. Add concurrency controls and rate limits as needed.

</Steps>

## Relevant Features

| Feature | Description |
|---------|------------|
| **[Retry Policies](/home/retry-policies)** | Configurable retries with exponential backoff, per task or per workflow |
| **[Concurrency Control](/home/concurrency)** | Limit parallel execution, prevent duplicate processing, fair scheduling |
| **[Rate Limits](/home/rate-limits)** | Throttle external API calls across all workers |
| **[Timeouts](/home/timeouts)** | Per-task and per-workflow timeouts to catch stuck tasks |
| **[On Failure Tasks](/home/on-failure-tasks)** | Run cleanup or alerting logic when a task fails |
| **[Logging](/home/logging)** | Structured logs visible in the dashboard alongside task execution |
| **[OpenTelemetry](/home/opentelemetry)** | Tracing and metrics for your observability stack |
| **[Bulk Operations](/home/bulk-retries-and-cancellations)** | Retry or cancel thousands of tasks from the dashboard |
| **[Autoscaling](/home/autoscaling-workers)** | Scale workers based on queue depth |

<Callout type="info">
  A practical migration strategy is to start with your most failure-prone tasks. These benefit the most from retry policies and observability. You can run Hatchet workers alongside your existing system during the transition.
</Callout>

## Migration Notes

### From Celery (Python)

Replace Celery's `@app.task` decorator with a Hatchet task definition. The main architectural change is that Hatchet uses a Postgres backend instead of Redis/RabbitMQ as a broker.

### From FastAPI BackgroundTasks

FastAPI's `BackgroundTasks` runs tasks in-process — they're lost if the server crashes or restarts. With Hatchet, tasks run in separate worker processes with delivery guarantees.

### From Bull/BullMQ (TypeScript)

Replace Bull's Redis-backed queues with Hatchet tasks. You get similar queue semantics (delayed jobs, rate limiting, priority) plus DAG workflows, child spawning, and a dashboard.

## Related Use Cases

<Cards>
  <Cards.Card title="Batch Processing" href="/home/use-cases/batch-processing">
    Process large volumes of items with fan-out parallelism and automatic retry.
  </Cards.Card>
  <Cards.Card title="Event-Driven Systems" href="/home/use-cases/event-driven">
    React to application events, webhooks, and cron schedules.
  </Cards.Card>
  <Cards.Card title="RAG & Indexing" href="/home/use-cases/rag-and-indexing">
    Build data processing pipelines with rate limiting and retry.
  </Cards.Card>
  <Cards.Card title="AI Agents" href="/home/use-cases/ai-agents">
    Orchestrate long-running AI agent loops with durable execution.
  </Cards.Card>
</Cards>

## Next Steps

- [Tasks](/home/your-first-task) — define your first Hatchet task
- [Workers](/home/workers) — configure and deploy workers
- [Running Tasks](/home/running-your-task) — trigger tasks from your application
- [Retry Policies](/home/retry-policies) — configure automatic retry behavior
