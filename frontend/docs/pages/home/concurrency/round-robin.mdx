import { Tabs } from "nextra/components";
import UniversalTabs from "../../../components/UniversalTabs";
import { GithubSnippet, getSnippets } from "@/components/code";

export const ConcurrencyPy = {
  path: "examples/concurrency_limit_rr/worker.py",
};
export const ConcurrencyTs = {
  path: "src/v1/examples/concurrency-rr/workflow.ts",
};

export const getStaticProps = ({}) =>
  getSnippets([ConcurrencyPy, ConcurrencyTs]);

# The `GROUP_ROUND_ROBIN` Concurrency Limit Strategy in Hatchet

Hatchet's `GROUP_ROUND_ROBIN` concurrency limit strategy is an advanced way to manage resource contention in your workflows while ensuring fair distribution of resources across different groups of tenants, users, or other concurrency key. This strategy allows you to process workflow instances in a round-robin fashion within each group, as defined by a key function.

## How it works

When a new workflow instance is triggered, the `GROUP_ROUND_ROBIN` strategy will:

1. Determine the group that the instance belongs to based on the `key` function defined in the workflow's concurrency configuration.
2. Check if there are any available slots for the instance's group based on the `maxRuns` limit of available workers.
3. If a slot is available, the new workflow instance starts executing immediately.
4. If no slots are available, the new workflow instance is added to a queue for its group.
5. When a running workflow instance completes and a slot becomes available for a group, the next queued instance for that group (in round-robin order) is dequeued and starts executing.

This strategy ensures that workflow instances are processed fairly across different groups, preventing any one group from monopolizing the available resources. It also helps to reduce latency for instances within each group, as they are processed in a round-robin fashion rather than strictly in the order they were triggered.

## When to use `GROUP_ROUND_ROBIN`

The `GROUP_ROUND_ROBIN` strategy is particularly useful in scenarios where:

- You have multiple clients or users triggering workflow instances, and you want to ensure fair resource allocation among them.
- You want to process instances within each group in a round-robin fashion to minimize latency and ensure that no single instance within a group is starved for resources.
- You have long-running workflow instances and want to avoid one group's instances monopolizing the available slots.

Keep in mind that the `GROUP_ROUND_ROBIN` strategy may not be suitable for all use cases, especially those that require strict ordering or prioritization of the most recent events.

## How to use `GROUP_ROUND_ROBIN`

To use the `GROUP_ROUND_ROBIN` concurrency limit strategy, define a `concurrency` configuration in your workflow definition:

CEL expressions are evaluated on the Hatchet engine (not in your worker) and can be used to extract values from the workflow input or [additional metadata](/features/additional-metadata).

<UniversalTabs items={['Python', 'Typescript', 'Go']}>
  <Tabs.Tab>

<GithubSnippet src={ConcurrencyPy} target="Workflow" />

  </Tabs.Tab>
  <Tabs.Tab>

<GithubSnippet src={ConcurrencyTs} target="Workflow" />

  </Tabs.Tab>
  <Tabs.Tab>

{/* TODO V1 DOCS -- Go example here */}

```go
import (
  "github.com/hatchet-dev/hatchet/pkg/client/types"
  "github.com/hatchet-dev/hatchet/pkg/worker"
)

type MyUser struct {
    UserId string `json:"user_id"`
}

err = w.RegisterWorkflow(
    &worker.WorkflowJob{
        Name: "concurrency-limit-per-user",
        On: worker.Events("concurrency-test-event"),
        Description: "This limits concurrency to 10 run at a time per user.",
        Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.GroupRoundRobin),
        Steps: []*worker.WorkflowStep{
            // your steps here...
        },
    },
)

```

  </Tabs.Tab>
</UniversalTabs>

> NOTE: Only one of `key` or `expression` should be provided, not both.

With this configuration, Hatchet will automatically manage your workflow's concurrency, processing instances within each group in a round-robin fashion and ensuring fair distribution of resources across groups.
