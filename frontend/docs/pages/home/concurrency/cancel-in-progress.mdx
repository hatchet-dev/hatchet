import { Tabs, Callout } from "nextra/components";
import UniversalTabs from "../../../components/UniversalTabs";
import { GithubSnippet, getSnippets } from "@/components/code";

export const ConcurrencyPy = {
  path: "examples/concurrency_limit/worker.py",
};

export const getStaticProps = ({}) => getSnippets([ConcurrencyPy]);

# The `CANCEL_IN_PROGRESS` Concurrency Limit Strategy in Hatchet

Hatchet's `CANCEL_IN_PROGRESS` concurrency limit strategy is a powerful tool for managing resource contention in your workflows. This strategy allows you to cancel currently running workflow instances to free up slots for new instances when the concurrency limit is reached.

## How it works

When a workflow run finishes and the concurrency limit is reached for the workflow version and group key, the `CANCEL_IN_PROGRESS` strategy will:

1. Fetch all currently running workflow runs for the given workflow version and concurrency key.
2. Fetch the queued workflow runs for the same workflow version and group key, up to the maximum number of concurrent runs allowed.
3. Cancel the oldest running workflow runs to make room for the queued runs, ensuring that there is space for all the queued runs to start executing.
4. Start executing the queued workflow runs in the freed-up slots.

This strategy ensures that queued workflow runs can start executing as soon as possible, even if the concurrency limit is reached, by canceling older running instances.

## When to use `CANCEL_IN_PROGRESS`

The `CANCEL_IN_PROGRESS` strategy is particularly useful in scenarios where:

- You have long-running workflow instances that may become stale or irrelevant if newer instances are triggered.
- You want to prioritize processing the most recent data or events, even if it means canceling older workflow instances.
- You have resource-intensive workflows where it's more efficient to cancel an in-progress instance and start a new one than to wait for the old instance to complete.
- Your user UI allows for multiple inputs, but only the most recent is relevant (i.e. chat messages, form submissions, etc.).

However, it's important to note that canceling a workflow instance may leave your system in an inconsistent state if the canceled instance was in the middle of updating a resource. Make sure to design your workflows to handle cancellation gracefully and ensure data consistency.

{/* TODO V1 DOCS - Add back link to cancellation docs on `handle cancellation gracefully` when we write those */}

## How to use `CANCEL_IN_PROGRESS`

To use the `CANCEL_IN_PROGRESS` concurrency limit strategy, define a `concurrency` configuration in your workflow definition:

<UniversalTabs items={['Python', 'Typescript']}>
{/* <UniversalTabs items={['Python', 'Typescript', 'Go']}> TODO V1 DOCS -- Add this back */}

  <Tabs.Tab>

<GithubSnippet src={ConcurrencyPy} target="Workflow" />

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
hatchet.workflow<SimpleInput, SimpleOutput>({
  name: "simple-concurrency",
  concurrency: {
    maxRuns: 100,
    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
    expression: "input.GroupKey",
  },
});
```

  </Tabs.Tab>
  {/* <Tabs.Tab>
TODO V1 DOCS -- Go example
```go
import (
  "github.com/hatchet-dev/hatchet/pkg/client/types"
  "github.com/hatchet-dev/hatchet/pkg/worker"
)

type MyUser struct {
UserId string `json:"user_id"`
}

err = w.RegisterWorkflow(
&worker.WorkflowJob{
Name: "concurrency-limit-per-user",
On: worker.Events("concurrency-test-event"),
Description: "This limits concurrency to 1 run at a time per user.",
Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.CancelInProgress),
Steps: []\*worker.WorkflowStep{
// your steps here...
},
},
)

```

  </Tabs.Tab> */}

 CEL expressions are evaluated on the Hatchet engine (not in your worker) and can be used to extract values from the workflow input or [additional metadata](../additional-metadata.mdx).


In this example:

- `maxRuns` sets the maximum number of concurrent instances allowed for this workflow.
- `limitStrategy` is set to `CANCEL_IN_PROGRESS`, indicating that when the concurrency limit is reached, currently running instances should be canceled to make room for new ones.
- `expression` (recommended) is a CEL expression that is used to determine the concurrency key. In this example, the expression is `input.group_key`, which means that instances are grouped by `group_key`.

</UniversalTabs>

<Callout type="info">
 Note that only one of `key` or `expression` should be provided, not both.
</Callout>

With this configuration, Hatchet will automatically manage your workflow's concurrency, canceling in-progress instances as needed to ensure that new instances can start executing immediately.

Remember to design your workflows to handle cancellation gracefully, and consider using checkpointing or idempotency techniques to ensure data consistency in the face of canceled instances.
```
