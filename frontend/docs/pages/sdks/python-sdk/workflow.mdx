import { Callout } from "nextra/components";

# Workflow Configuration

To create a workflow, simply create a new function and use the `hatchet.function` decorator to
define the structure of your workflow. For example, a simple workflow would look like:

```py
from hatchet_sdk import Context
from hatchet_sdk.v2.hatchet import Hatchet

hatchet = Hatchet(debug=True)


@hatchet.function(on_events=["user:create"])
def hatchet_func(ctx: Context) -> None:
    print("Running hatchet_func")


worker = hatchet.worker(
    name="test-worker",
    max_runs=5,
)
worker.start()
```

You'll notice that the workflow defines a workflow trigger (in this case, `on_events`). Each
function must accept a `context` argument. The `context` argument is a `Context` object, which
contains information about the workflow, such as the input data and the output data of any previous
workflows.

To create multi-step workflows (ie DAGs), check out [the docs on creating a DAG Workflow](./dag)

## Workflow Triggers

You can define the following automatic triggers for workflows:

- `on_events`: Trigger the workflow when a specific event is sent to the Hatchet API. See the documentation for [running workflows via events](./run-workflow-events) for more information.
- `on_crons`: Trigger the workflow on a cron schedule. See the documentation for [running workflows via cron schedules](./run-workflow-cron) for more information.

## Retrieving Workflow Input Data

You can get access to the workflow's input data, such as the event data or other specified input data, by using the `context.workflow_input()` method on the `context`. For example, given the following event:

```json
{
  "name": "test"
}
```

You can get access to the event data by doing the following:

```py
@hatchet.function(on_events=["user:create"])
def hatchet_func(ctx: Context) -> None:
    print("executed hatchet_func", context.workflow_input())
    pass
```

## Function Outputs

Function outputs should be a `dict` and are optional. For example:

```py
@hatchet.function(on_events=["user:create"])
def hatchet_func(ctx: Context) -> None:
    return {
        "my-func-output": "test"
    }
```

Future functions can access this output by calling `context.step_output("<func>")`. In this example, a future step could access this data via `context.step_output("hatchet_func")`.

## Sync vs Async Functions

You can define async steps by using the `async` keyword on the step method. For example:

```py
@hatchet.function(on_events=["user:create"])
async def hatchet_func(ctx: Context) -> None:
    print("executed hatchet_func", context.workflow_input())
    await asyncio.sleep(1)
```

When functions are run with `async`, they will be executed in the main thread using the default
asyncio event loop. If an asyncio event loop is not set when the worker is started with
`worker.start`, one will be created.

If you are using `async` functions, **make sure you are not blocking the event loop**. If you are
running blocking code, decorating the method with only `def` will execute it in a separate thread.
You can also call `asyncio.run` within your `def` method if you're in need of using `async/await`
within a `def` method, but please ensure that you are not using a third-party dependency which
expects a shared event loop.

As a quick rule of thumb:

- If you are using `async/await`, use `async def` and ensure you are not blocking the event loop.
- If you are running blocking code, use `def` and ensure you are not using third-party dependencies
  that expect a shared event loop.

## Timeouts

**The default timeout on Hatchet is 60 seconds per step run**.

You can declare a timeout for a function by passing `timeout` to the `hatchet.function` decorator. Timeouts
are strings in the format of `1h`, `1m`, `1s`, etc. For example, to timeout a step after 5 minutes,
you can do the following:

```py
@hatchet.function(timeout="5m")
def hatchet_func(self, context):
    print("executed hatchet_func")
```

## Termination, Sleeps and Threads

Hatchet spawns a new thread per function, which means that there is a risk of thread leakage if your
code is busy outside of the python interpreter. For example, this can happen if you call
`time.sleep` within a function. Consider using an `async` method with `await asyncio.sleep` instead.

You can also determine whether to exit the thread by calling `context.done()` within a function, which
returns true if the step has been cancelled. For example:

```py
@hatchet.function(timeout="2s")
def hatchet_func(self, context):
    while True:
        # this step will gracefully exit after 2 seconds
        if context.done():
            break
```

If you need control over cancellation, you can also use `context.cancel()` to cancel the current
step, though this is not recommended.

## Durable Functions

<Callout type="info">
  To learn more about Durable Execution as a concept, check out our writeup on
  it [here](https://docs.hatchet.run/home/features/durable-execution).
</Callout>

You can define a Durable Function in a similar way to a normal function, create a new function and
use the `hatchet.durable` decorator.

For example, a durable workflow would look like:

```py
from hatchet_sdk import DurableContext
from hatchet_sdk.v2.hatchet import Hatchet

hatchet = Hatchet(debug=True)


@hatchet.durable()
def hatchet_func(ctx: DurableContext) -> None:
    print("Running hatchet_func")


worker = hatchet.worker(
    name="test-worker",
    max_runs=5,
)
worker.start()
```

The main advantage of using a Durable Function is its ability to resume running a multitude of
functions from a mid-point after a failure without needing to rerun all the previous successful
runs.

An example:

```py
import asyncio

from hatchet_sdk import Context
from hatchet_sdk.v2.callable import DurableContext
from hatchet_sdk.v2.hatchet import Hatchet

hatchet = Hatchet(debug=True)


@hatchet.function()
def my_func(ctx: Context):
    return {"my_func": "testing123"}


@hatchet.durable()
async def my_durable_func(ctx: DurableContext):
    function_runs = []
    n = ctx.workflow_input().get("n", 20)

    for i in range(n):
        function_runs.append(
            ctx.run(my_func, {"test": "test"}, key=f"my_func_{i}").result()
        )

    result = await asyncio.gather(*function_runs)
    ctx.log(result)

    return {"my_durable_func": result}


def main():
    worker = hatchet.worker("test-worker", max_runs=5)

    hatchet.admin.run(my_durable_func, {"test": "test"})

    worker.start()
```
