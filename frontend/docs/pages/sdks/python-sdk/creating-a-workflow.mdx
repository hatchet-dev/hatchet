# Creating a Workflow

To create a workflow, simply create a new class and use the `hatchet.workflow` and `hatchet.step` decorators to define the structure of your workflow. For example, a simple 2-step workflow would look like:

```py
from hatchet_sdk import Hatchet

hatchet = Hatchet()

@hatchet.workflow(on_events=["user:create"])
class MyWorkflow:
    @hatchet.step()
    def step1(self, context):
        print("executed step1")
        pass

    @hatchet.step(parents=["step1"])
    def step2(self, context):
        print("executed step2")
        pass
```

You'll notice that the workflow defines a workflow trigger (in this case, `on_events`), and the workflow definition. The workflow definition is a series of steps, which can be defined using the `hatchet.step` decorator. Each step must be a method on the class, and must accept a `context` argument. The `context` argument is a `Context` object, which contains information about the workflow, such as the input data and the output data of previous steps.

To create multi-step workflows, you can use `parents` to define the steps which the current step depends on.

## Getting Access to the Input Data

You can get access to the workflow's input data, such as the event data or other specified input data, by using the `context.workflow_input()` method on the `context`. For example, given the following event:

```json
{
  "name": "test"
}
```

You can get access to the event data by doing the following:

```py
@hatchet.workflow(on_events=["user:create"])
class MyWorkflow:
    @hatchet.step()
    def step1(self, context : Context):
        print("executed step1", context.workflow_input())
        pass
```

## Step Outputs

Step outputs should be a `dict` and are optional. For example:

```py
@hatchet.workflow(on_events=["user:create"])
class MyWorkflow:
    @hatchet.step()
    def step1(self, context : Context):
        return {
            "step-1-output": "test"
        }
```

Future steps can access this output by calling `context.step_output("<step>")`. In this example, a future step could access this data via `context.step_output("step1")`.

## Cron Schedules

You can declare a cron schedule by passing `on_crons` to the `hatchet.workflow` decorator. For example, to trigger a workflow every 5 minutes, you can do the following:

```go
from hatchet_sdk import Hatchet

hatchet = Hatchet()

@hatchet.workflow(on_crons=["*/5 * * * *"])
class MyWorkflow:
    @hatchet.step()
    def step1(self, context):
        print("executed step1")
        pass

    @hatchet.step(parents=["step1"])
    def step2(self, context):
        print("executed step2")
        pass
```

## Timeouts

**The default timeout on Hatchet is 60 seconds per step run**.

You can declare a timeout for a step by passing `timeout` to the `hatchet.step` decorator. Timeouts are strings in the format of `1h`, `1m`, `1s`, etc. For example, to timeout a step after 5 minutes, you can do the following:

```py
@hatchet.step(timeout="5m")
def step1(self, context):
    print("executed step1")
    pass
```

## Concurrency Limits and Fairness

> **Note:** this feature is currently in beta, and currently only supports a concurrency strategy which terminates the oldest running workflow run to make room for the new one. This will be expanded in the future to support other strategies.\*\*

By default, there are no concurrency limits for Hatchet workflows. Workflow runs are immediately executed as soon as they are triggered (by an event, cron, or schedule). However, you can enforce a concurrency limit by decorating a custom function with `hatchet.concurrency`. This function returns a **concurrency group key**, which is a string that is used to group concurrent executions. **Note that this function should not also be used as a `hatchet.step`.** For example, the following workflow will only allow 5 concurrent executions for any workflow execution of `ConcurrencyDemoWorkflow`, since the key is statically set to `concurrency-key`:

```py
@hatchet.workflow(on_events=["concurrency-test"])
class ConcurrencyDemoWorkflow:
    @hatchet.concurrency(max_runs=5)
    def concurrency(self, context) -> str:
        return "concurrency-key"

    @hatchet.step()
    def step1(self, context):
        print("executed step1")
        pass
```

### Use-Case: Enforcing Per-User Concurrency Limits

You can use the custom concurrency function to enforce per-user concurrency limits. For example, the following workflow will only allow 1 concurrent execution per user:

```py
@hatchet.workflow(on_events=["concurrency-test"])
class ConcurrencyDemoWorkflow:
    @hatchet.concurrency(max_runs=1)
    def concurrency(self, context) -> str:
        return context.workflow_input()["user_id"]

    @hatchet.step()
    def step1(self, context):
        print("executed step1")
        pass
```

This same approach can be used for:

- Setting concurrency for a specific user session by `session_id` (i.e. multiple chat messages sent)
- Limiting data or document ingestion by setting an input hash or on-file key.
- Rudimentary fairness rules by limiting groups per tenant to a certain number of concurrent executions.

## Termination, Sleeps and Threads

Hatchet spawns a new thread per step, which means that there is a risk of thread leakage if your code is busy outside of the python interpreter. For example, this can happen if you call `time.sleep` within a step. To avoid this, you can use `context.sleep` instead. For example:

```py
@hatchet.step()
def step1(self, context):
    context.sleep(5)
    pass
```

You can also determine whether to exit the thread by calling `context.done()` within a step, which returns true if the step has been cancelled. For example:

```py
@hatchet.step(timeout="2s")
def step1(self, context):
    while True:
        # this step will gracefully exit after 2 seconds
        if context.done():
            break
        pass
```

If you need control over cancellation, you can also use `context.cancel()` to cancel the current step, though this is not recommended.

## Logging

Hatchet comes with a built-in logging view where you can push debug logs from your workflows. To use this, you can use the `context.log` method. For example:

```py
@hatchet.workflow(on_events=["user:create"],schedule_timeout="10m")
class LoggingWorkflow:
    @hatchet.step()
    def logger(self, context : Context):

        for i in range(1000):
            context.log(f"Logging message {i}")

        return {
            "step1": "completed",
        }
```

Each step is currently limited to 1000 log lines.
