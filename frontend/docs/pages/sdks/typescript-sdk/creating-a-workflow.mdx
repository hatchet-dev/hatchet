# Creating a Workflow

To create a workflow, simply create a new `Workflow` object.
For example, a simple 2-step workflow would look like:

```ts
import Hatchet, { Workflow } from "@hatchet-dev/typescript-sdk";

const hatchet = Hatchet.init();

const workflow: Workflow = {
  id: "example",
  description: "test",
  on: {
    event: "user:create",
  },
  steps: [
    {
      name: "step1",
      run: (ctx) => {
        console.log("executed step1!");
        return { step1: "step1" };
      },
    },
    {
      name: "step2",
      parents: ["step1"],
      run: (ctx) => {
        console.log("executed step2!");
        return { step2: "step2" };
      },
    },
  ],
};
```

You'll notice that the workflow defines a workflow trigger (in this case, `on_events`), and the workflow definition. The workflow definition includes a series of steps which is simply an array of `Step` objects.
Each step has a `run` prop which is a function that with a `context` augment. The `context` argument is a `Context` object, which contains information about the workflow, such as the input data and the output data of previous steps.

To create multi-step workflows, you can use `parents` to define the steps which the current step depends on. In the example, `step2` will not invoke until after `step1` completes.

## Getting Access to the Workflow Input Data

You can get access to the workflow's input data simply by calling `ctx.workflowInput()`.

Here's an example `Step` which accesses the workflow input:

```ts
const stepPrintsInput: Step = {
  name: "step2",
  parents: ["step1"],
  run: (ctx) => {
    console.log("executed step2!", ctx.workflowInput("name"));
  },
};
```

Given the following event:

```json
{
  "name": "John"
}
```

The console will log:

```
executed step2! John
```

## Step Outputs

Step outputs should be a of type `Record<string, any>`, should be `JSON` serializable, and are optional. For example:

```ts
const stepReturnsData: Step = {
  name: "step2",
  run: (ctx) => {
    return { awesome: "data" };
  },
};
```

Future steps can access this output through the context (`ctx`) parameter `ctx.stepOutput("<step_name>")`. In this example, a future step could access this data via `context.stepOutput("step2")`:

```ts
const futureStep: Step = {
  name: "step3",
  run: (ctx) => {
    const uppercaseStep2 = ctx.stepOutput("step2")["awesome"].toUpperCase();
    return { uppercase: uppercaseStep2 };
  },
};
```

Remember, a step that depends on previous step data should include this dependency in the `parents` array.

## Cron Schedules

You can declare a cron schedule by defining `on_crons` in the `Workflow` object. For example, to trigger a workflow every 5 minutes, you can do the following:

```ts
import Hatchet from "@hatchet-dev/typescript-sdk";
import { Workflow } from "@hatchet/workflow";

const hatchet = Hatchet.init();

const workflow: Workflow = {
  id: "example",
  description: "test",
  on: {
    cron: "*/5 * * * *",
  },
  steps: [
    {
      name: "step1",
      run: (input, ctx) => {
        console.log("executed step1!");
        return { step1: "step1" };
      },
    },
    {
      name: "step2",
      parents: ["step1"],
      run: (input, ctx) => {
        console.log("executed step2!", input);
        return { step2: "step2" };
      },
    },
  ],
};
```

## Concurrency Limits and Fairness

> **Note:** this feature is currently in beta, and currently only supports a concurrency strategy which terminates the oldest running workflow run to make room for the new one. This will be expanded in the future to support other strategies.\*\*

By default, there are no concurrency limits for Hatchet workflows. Workflow runs are immediately executed as soon as they are triggered (by an event, cron, or schedule). However, you can enforce a concurrency limit by adding a `concurrency` configuration to your workflow declaration. This configuration includes a key which takes a function that returns a **concurrency group key**, which is a string that is used to group concurrent executions. **Note that this function should not also be used as a `hatchet.step`.** For example, the following workflow will only allow 5 concurrent executions for any workflow execution of `ConcurrencyDemoWorkflow`, since the key is statically set to `concurrency-key`:

```ts
const workflow: Workflow = {
  id: "concurrency-example",
  description: "test",
  on: {
    event: "concurrency:create",
  },
  concurrency: {
    name: "basic-concurrency",
    key: (ctx) => "concurrency-key",
  },
  steps: [
    {
      name: "step1",
      run: async (ctx) => {
        const { data } = ctx.workflowInput();
        const { signal } = ctx.controller;

        if (signal.aborted) throw new Error("step1 was aborted");

        console.log("starting step1 and waiting 5 seconds...", data);
        await sleep(5000);

        if (signal.aborted) throw new Error("step1 was aborted");

        // NOTE: the AbortController signal can be passed to many http libraries to cancel active requests
        // fetch(url, { signal })
        // axios.get(url, { signal })

        console.log("executed step1!");
        return { step1: `step1 results for ${data}!` };
      },
    },
    {
      name: "step2",
      parents: ["step1"],
      run: (ctx) => {
        console.log(
          "executed step2 after step1 returned ",
          ctx.stepOutput("step1"),
        );
        return { step2: "step2 results!" };
      },
    },
  ],
};
```

The argument `limitStrategy` to the `concurrency` configuration can be set to either `CANCEL_IN_PROGRESS` (the default, documented above), or `GROUP_ROUND_ROBIN`. See documentation for the `GROUP_ROUND_ROBIN` strategy below.

### Cancellation Signalling

When a concurrent workflow is already running, Hatchet will send a cancellation signal to the step via it's context. For now, you must handle this signal to exit the step at a logical point:

```ts
{
    "step1",
    run: async (ctx) => {
      const { data } = ctx.workflowInput();
      const { signal } = ctx.controller;

      if (signal.aborted) throw new Error("step1 was aborted");

      console.log("starting step1 and waiting 5 seconds...", data);
      await sleep(5000);

      if (signal.aborted) throw new Error("step1 was aborted");

      // NOTE: the AbortController signal can be passed to many http libraries to cancel active requests
      // fetch(url, { signal })
      // axios.get(url, { signal })

      console.log("executed step1!");
      return { step1: `step1 results for ${data}!` };
    },
  },
```

### Use-Case: Enforcing Per-User Concurrency Limits

You can use the custom concurrency function to enforce per-user concurrency limits. For example, the following workflow will only allow 1 concurrent execution per user:

```py
const workflow: Workflow = {
  id: "concurrency-example",
  description: "test",
  on: {
    event: "concurrency:create",
  },
  concurrency: {
    name: "basic-concurrency",
    maxRuns: 1,
    key: (ctx) => ctx.workflowInput().userId,
  },
  // Rest of the workflow configuration
}
```

This same approach can be used for:

- Setting concurrency for a specific user session by `session_id` (i.e. multiple chat messages sent)
- Limiting data or document ingestion by setting an input hash or on-file key.
- Rudimentary fairness rules by limiting groups per tenant to a certain number of concurrent executions.

### Use-Case: Group Round Robin

You can distribute workflows fairly between tenants using the `GROUP_ROUND_ROBIN` option for `limitStrategy`. This will ensure that each distinct group gets a fair share of the concurrency limit. For example, let's say 5 workflows got queued in quick succession for keys `A`, `B`, and `C`:

```txt
A, A, A, A, A, B, B, B, B, B, C, C, C, C, C
```

If there is a maximum of 2 concurrent executions, the execution order will be:

```txt
A, B, C, A, B, C, A, B, C, A, B, C, A, B, C
```

This can be set in the `concurrency` configuration as follows:

```ts
const workflow: Workflow = {
  id: 'concurrency-example-rr',
  description: 'test',
  on: {
    event: 'concurrency:create',
  },
  concurrency: {
    name: 'multi-tenant-fairness',
    key: (ctx) => ctx.workflowInput().group,
    maxRuns: 2,
    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
  },
  steps: [...],
};
```

## Playground Values

Playground values are a way to override variables within a workflow from the Hatchet UI. For example, you could use this to make a prompt or temperature value for an LLM workflow configurable from the UI. These values can be set via the `ctx.playground` method:

```ts
await worker.registerWorkflow({
  id: "playground-demo",
  description: "This is a demo of the playground",
  steps: [
    {
      name: "playground",
      run: (ctx: Context<any, any>) => {
        const prompt = ctx.playground("prompt", "This is an example prompt");

        return { step1: playground };
      },
    },
  ],
});
```

This will then appear in the Hatchet UI under the `prompt` value.

## Logging

Hatchet comes with a built-in logging view where you can push debug logs from your workflows. To use this, you can use the `ctx.log` method. For example:

```ts
const workflow: Workflow = {
  id: "logger-example",
  description: "test",
  on: {
    event: "user:create",
  },
  steps: [
    {
      name: "logger-step1",
      run: async (ctx) => {
        for (let i = 0; i < 1000; i++) {
          ctx.log(`log message ${i}`);
        }

        return { step1: "completed step run" };
      },
    },
  ],
};
```

Each step is currently limited to 1000 log lines.
